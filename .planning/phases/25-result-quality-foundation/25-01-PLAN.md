---
phase: 25-result-quality-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rag-ingestion/src/bbj_rag/url_mapping.py
  - rag-ingestion/tests/test_url_mapping.py
  - rag-ingestion/sql/schema.sql
  - rag-ingestion/src/bbj_rag/models.py
  - rag-ingestion/src/bbj_rag/db.py
  - rag-ingestion/scripts/backfill_urls.py
autonomous: true

must_haves:
  truths:
    - "classify_source_type() correctly maps all 6 source URL prefixes to their source_type labels"
    - "map_display_url() transforms flare:// URLs to https://documentation.basis.cloud/BASISHelp/WebHelp/... URLs"
    - "map_display_url() passes through https:// URLs unchanged"
    - "map_display_url() wraps unmappable source URLs in brackets (e.g., [pdf://...])"
    - "Database schema includes source_type and display_url columns on the chunks table"
    - "Chunk INSERT SQL includes source_type and display_url values"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/url_mapping.py"
      provides: "classify_source_type() and map_display_url() pure functions"
      contains: "classify_source_type"
    - path: "rag-ingestion/tests/test_url_mapping.py"
      provides: "Unit tests covering all 6 source types for both functions"
      min_lines: 40
    - path: "rag-ingestion/sql/schema.sql"
      provides: "source_type TEXT and display_url TEXT columns on chunks table"
      contains: "source_type"
    - path: "rag-ingestion/src/bbj_rag/models.py"
      provides: "source_type and display_url fields on Document and Chunk models"
      contains: "display_url"
    - path: "rag-ingestion/src/bbj_rag/db.py"
      provides: "INSERT SQL and _chunk_to_params include source_type and display_url"
      contains: "display_url"
    - path: "rag-ingestion/scripts/backfill_urls.py"
      provides: "One-time script to populate source_type and display_url for existing chunks"
      contains: "backfill"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/url_mapping.py"
      to: "rag-ingestion/scripts/backfill_urls.py"
      via: "import and call classify_source_type + map_display_url"
      pattern: "from bbj_rag.url_mapping import"
    - from: "rag-ingestion/src/bbj_rag/db.py"
      to: "rag-ingestion/sql/schema.sql"
      via: "INSERT column list matches CREATE TABLE columns"
      pattern: "source_type.*display_url"
    - from: "rag-ingestion/src/bbj_rag/models.py"
      to: "rag-ingestion/src/bbj_rag/db.py"
      via: "Chunk fields mapped to INSERT params"
      pattern: "chunk\\.display_url"
---

<objective>
Create the URL mapping module with source type classification and display URL generation, add the corresponding database columns, update data models and DB insert layer, and build a backfill script for existing chunks.

Purpose: This is the data foundation for Phase 25. Every downstream change (search, API, MCP) depends on `source_type` and `display_url` being available on chunks. The backfill script ensures existing 50K+ chunks get these values without re-ingestion.

Output: Working url_mapping.py with unit tests, updated schema/models/db, and a runnable backfill script.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-result-quality-foundation/25-CONTEXT.md
@.planning/phases/25-result-quality-foundation/25-RESEARCH.md

@rag-ingestion/src/bbj_rag/models.py
@rag-ingestion/src/bbj_rag/db.py
@rag-ingestion/sql/schema.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create URL mapping module and unit tests</name>
  <files>
    rag-ingestion/src/bbj_rag/url_mapping.py
    rag-ingestion/tests/test_url_mapping.py
  </files>
  <action>
Create `rag-ingestion/src/bbj_rag/url_mapping.py` with two pure functions:

**`classify_source_type(source_url: str) -> str`:**
Returns the source type label based on `source_url` prefix. Mapping:
- `flare://` -> `"flare"`
- `pdf://` -> `"pdf"`
- `file://` -> `"bbj_source"`
- `mdx-dwc://` -> `"mdx"`
- `mdx-beginner://` -> `"mdx"`
- `mdx-db-modernization://` -> `"mdx"`
- `https://basis.cloud/advantage` -> `"wordpress"`
- `https://basis.cloud/knowledge-base` -> `"wordpress"`
- `https://documentation.basis.cloud/` -> `"web_crawl"`
- Anything else -> `"unknown"`

Use a list of `(prefix, label)` tuples checked in order with `source_url.startswith()`. No regex needed for classification.

**`map_display_url(source_url: str) -> str`:**
Returns the public-facing display URL. Rules:
- If `source_url` starts with `flare://Content/`: strip prefix, prepend `https://documentation.basis.cloud/BASISHelp/WebHelp/`
- If `source_url` starts with `https://`: return as-is (pass-through for WordPress and Web Crawl)
- Otherwise: return `[{source_url}]` (bracketed fallback for pdf://, file://, mdx-*//)

Include `__all__` with both function names.

**Unit tests in `test_url_mapping.py`:**
Test both functions with at least one example per source type:
- Flare: `flare://Content/bbjobjects/bbjapi/bbjapi.htm` -> source_type `"flare"`, display_url `https://documentation.basis.cloud/BASISHelp/WebHelp/bbjobjects/bbjapi/bbjapi.htm`
- PDF: `pdf://GuideToGuiProgrammingInBBj.pdf#some-slug` -> `"pdf"`, `[pdf://GuideToGuiProgrammingInBBj.pdf#some-slug]`
- BBj Source: `file://samples/DWCNavigator.bbj` -> `"bbj_source"`, `[file://samples/DWCNavigator.bbj]`
- MDX (all 3 prefixes): `mdx-dwc://...`, `mdx-beginner://...`, `mdx-db-modernization://...` -> `"mdx"`, bracketed
- WordPress Advantage: `https://basis.cloud/advantage/some-article/` -> `"wordpress"`, pass-through
- WordPress KB: `https://basis.cloud/knowledge-base/kb01220/` -> `"wordpress"`, pass-through
- Web Crawl: `https://documentation.basis.cloud/BASISHelp/WebHelp/...` -> `"web_crawl"`, pass-through
- Unknown: `some://other` -> `"unknown"`, bracketed

Follow existing test patterns (pytest, no fixtures needed for pure functions).
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/test_url_mapping.py -v` -- all tests pass.
  </verify>
  <done>
classify_source_type returns correct label for all 6+ source types. map_display_url returns HTTPS URLs for Flare/WordPress/WebCrawl and bracketed fallbacks for PDF/BBjSource/MDX. All unit tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Schema migration, model updates, DB layer, and backfill script</name>
  <files>
    rag-ingestion/sql/schema.sql
    rag-ingestion/src/bbj_rag/models.py
    rag-ingestion/src/bbj_rag/db.py
    rag-ingestion/scripts/backfill_urls.py
  </files>
  <action>
**schema.sql changes:**
Add two new columns to the `CREATE TABLE IF NOT EXISTS chunks` statement, after the `deprecated` column and before the `embedding` column:
```sql
source_type     TEXT            NOT NULL DEFAULT '',
display_url     TEXT            NOT NULL DEFAULT '',
```
Add an index for source_type (for diversity queries):
```sql
CREATE INDEX IF NOT EXISTS idx_chunks_source_type ON chunks (source_type);
```

**models.py changes:**
Add `source_type: str = ""` and `display_url: str = ""` fields to both the `Document` and `Chunk` models. Add them after `deprecated` and before `metadata`. In `Chunk.from_content()`, add `source_type: str = ""` and `display_url: str = ""` parameters and pass them through to the constructor.

**db.py changes:**
Update `_INSERT_CHUNK_SQL` to include `source_type` and `display_url` in both the column list and VALUES placeholders (add 2 more `%s`). Update `_chunk_to_params()` to include `chunk.source_type` and `chunk.display_url` in the returned tuple, positioned to match the INSERT column order. Update `bulk_insert_chunks()` to include `source_type` and `display_url` in the COPY column list, the staging table INSERT/SELECT, and add `"text"` entries to `set_types()`. Also add `chunk.source_type` and `chunk.display_url` to the `copy.write_row()` list.

**scripts/backfill_urls.py:**
Create a standalone script that:
1. Connects to the database using `get_connection_from_settings()` and `Settings()`
2. Runs `ALTER TABLE chunks ADD COLUMN IF NOT EXISTS source_type TEXT NOT NULL DEFAULT ''` and same for `display_url` (idempotent migration)
3. Creates the `idx_chunks_source_type` index if not exists
4. Selects all distinct `source_url` values where `source_type = ''` or `display_url = ''`
5. For each distinct source_url, calls `classify_source_type()` and `map_display_url()`
6. Batch-updates chunks using `UPDATE chunks SET source_type = %s, display_url = %s WHERE source_url = %s AND (source_type = '' OR display_url = '')`
7. Commits after each batch of 1000 distinct source_urls
8. Logs progress and final counts

Import `classify_source_type` and `map_display_url` from `bbj_rag.url_mapping`. Use `bbj_rag.config.Settings` for DB connection. Include a `__main__` guard and make it runnable via `uv run python scripts/backfill_urls.py`.
  </action>
  <verify>
1. `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/ -v -k "not test_mcp and not test_e2e"` -- existing tests still pass (model changes are backward compatible via defaults).
2. `uv run python -c "from bbj_rag.models import Chunk; c = Chunk.from_content(source_url='x', title='t', doc_type='d', content='c', generations=['bbj'], source_type='flare', display_url='https://example.com'); print(c.source_type, c.display_url)"` -- prints `flare https://example.com`.
3. Visually verify `_INSERT_CHUNK_SQL` has 12 columns (was 10) and 12 `%s` placeholders.
  </verify>
  <done>
Schema DDL includes source_type and display_url columns with index. Document and Chunk models have the new fields with empty-string defaults. db.py INSERT and COPY operations include the new columns. Backfill script exists and is syntactically valid. Existing tests pass.
  </done>
</task>

</tasks>

<verification>
1. Unit tests for url_mapping pass: `uv run pytest tests/test_url_mapping.py -v`
2. Existing test suite still passes: `uv run pytest tests/ -v -k "not test_mcp and not test_e2e"`
3. Chunk.from_content() accepts and stores source_type and display_url
4. backfill_urls.py script is importable and syntactically valid: `uv run python -c "import scripts.backfill_urls"` or `uv run python scripts/backfill_urls.py --help` (if help flag added)
</verification>

<success_criteria>
- url_mapping.py exists with classify_source_type() and map_display_url() covering all 6 source types
- test_url_mapping.py passes all tests
- schema.sql defines source_type and display_url columns
- models.py Document and Chunk have source_type and display_url fields
- db.py INSERT SQL includes the 2 new columns
- backfill_urls.py script exists and uses url_mapping functions
- All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/25-result-quality-foundation/25-01-SUMMARY.md`
</output>
