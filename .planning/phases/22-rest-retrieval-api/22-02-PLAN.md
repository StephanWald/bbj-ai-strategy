---
phase: 22-rest-retrieval-api
plan: 02
type: execute
wave: 2
depends_on: ["22-01"]
files_modified:
  - rag-ingestion/src/bbj_rag/api/routes.py
  - rag-ingestion/src/bbj_rag/api/schemas.py
  - rag-ingestion/src/bbj_rag/health.py
autonomous: true

must_haves:
  truths:
    - "POST /search with generation=dwc returns only chunks where generations array contains 'dwc'"
    - "POST /search with generation=bbj-gui normalizes to bbj_gui and filters correctly"
    - "GET /health returns {status: healthy, checks: {database: ok, ollama: ok}} with 200 when both are up"
    - "GET /health returns 503 with status degraded when one component is down, unhealthy when both are down"
    - "GET /stats returns total_chunks, by_source (doc_type counts), and by_generation (unnested generation counts)"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/api/routes.py"
      provides: "/stats endpoint"
      contains: "async def stats"
    - path: "rag-ingestion/src/bbj_rag/api/schemas.py"
      provides: "StatsResponse Pydantic model"
      contains: "class StatsResponse"
    - path: "rag-ingestion/src/bbj_rag/health.py"
      provides: "Pool-based health checks with readiness semantics"
      contains: "request.app.state.pool"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/health.py"
      to: "app.state.pool"
      via: "health endpoint uses pool for DB check instead of standalone psycopg.connect"
      pattern: "pool\\.connection"
    - from: "rag-ingestion/src/bbj_rag/api/routes.py"
      to: "chunks table"
      via: "stats endpoint queries chunks table with GROUP BY doc_type and unnest(generations)"
      pattern: "unnest.*generations"
---

<objective>
Add generation filtering with normalization, /stats endpoint, and extend /health with pool-based checks and readiness semantics.

Purpose: Completes the REST API surface -- generation filtering enables the MCP server to request generation-specific results (e.g., only DWC docs), /stats gives visibility into the ingested corpus, and the health endpoint upgrade uses the connection pool instead of creating throwaway connections.

Output: Full REST API with /search (including generation filter + normalization), /stats, and /health endpoints.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-rest-retrieval-api/22-CONTEXT.md
@.planning/phases/22-rest-retrieval-api/22-RESEARCH.md
@.planning/phases/22-rest-retrieval-api/22-01-SUMMARY.md
@rag-ingestion/src/bbj_rag/health.py
@rag-ingestion/src/bbj_rag/api/routes.py
@rag-ingestion/src/bbj_rag/api/schemas.py
@rag-ingestion/src/bbj_rag/api/deps.py
@rag-ingestion/src/bbj_rag/app.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add /stats endpoint and StatsResponse schema</name>
  <files>
    rag-ingestion/src/bbj_rag/api/schemas.py
    rag-ingestion/src/bbj_rag/api/routes.py
  </files>
  <action>
**schemas.py:** Add `StatsResponse` Pydantic model:

```python
class StatsResponse(BaseModel):
    total_chunks: int
    by_source: dict[str, int]  # doc_type -> count
    by_generation: dict[str, int]  # generation tag -> count
```

**routes.py:** Add GET /stats endpoint:

```python
@router.get("/stats", response_model=StatsResponse)
async def stats(conn: AsyncConnection = Depends(get_conn)) -> StatsResponse:
```

The handler should execute three queries using `async with conn.cursor() as cur`:

1. Total count: `SELECT count(*) FROM chunks` -- extract `row[0]` as total
2. By source (doc_type): `SELECT doc_type, count(*) FROM chunks GROUP BY doc_type ORDER BY count(*) DESC` -- build dict from rows
3. By generation (unnested): `SELECT g, count(*) FROM chunks, unnest(generations) AS g GROUP BY g ORDER BY count(*) DESC` -- build dict from rows

Return `StatsResponse(total_chunks=total, by_source=by_source, by_generation=by_generation)`.

Wrap the entire block in try/except for database errors and raise `HTTPException(status_code=503, detail=f"Database query failed: {exc}")`.

Also verify that the generation normalization in the /search endpoint (from Plan 22-01) correctly handles the `bbj-gui` -> `bbj_gui` transformation. The normalization should already be `body.generation.replace("-", "_")` -- confirm this exists and is correct. If it was implemented differently, ensure it matches the CONTEXT.md decision.
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run python -c "from bbj_rag.api.schemas import StatsResponse; print(StatsResponse.model_json_schema())"` to confirm StatsResponse schema. Run `uv run python -c "from bbj_rag.api.routes import router; paths = [r.path for r in router.routes]; assert '/stats' in paths; print('stats route OK')"` to confirm /stats is registered. Run `uv run pytest tests/ -x -q` to ensure nothing is broken.
  </verify>
  <done>
GET /stats endpoint exists, returns StatsResponse with total_chunks, by_source, and by_generation. Generation normalization in /search replaces hyphens with underscores. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend /health with pool-based checks and readiness semantics</name>
  <files>
    rag-ingestion/src/bbj_rag/health.py
  </files>
  <action>
Rewrite `/health` endpoint to use the connection pool from `app.state` instead of creating standalone `psycopg.connect()` connections. This eliminates the overhead of creating a new connection per health check and ensures the health check validates pool connectivity.

**Changes to health.py:**

1. **Add `Request` parameter** to the endpoint: `async def health(request: Request) -> JSONResponse:`

2. **Replace database check** -- Instead of `psycopg.connect(...)` with manual connection management, use the pool:
   ```python
   pool = request.app.state.pool
   async with pool.connection() as conn:
       await conn.execute("SELECT 1")
   checks["database"] = "ok"
   ```
   If pool is not available on app.state (e.g., during early startup before pool init), fall back to the existing standalone connection approach. Use `getattr(request.app.state, 'pool', None)` to check.

3. **Add readiness semantics** -- Replace the binary healthy/degraded with three-tier:
   - `healthy` (200): all checks pass
   - `degraded` (503): some checks pass, some fail
   - `unhealthy` (503): all checks fail

   Logic:
   ```python
   ok_count = sum(1 for v in checks.values() if v == "ok")
   if ok_count == len(checks):
       status, status_code = "healthy", 200
   elif ok_count > 0:
       status, status_code = "degraded", 503
   else:
       status, status_code = "unhealthy", 503
   ```

4. **Remove direct Settings() and psycopg.connect() imports** if no longer needed for the database check (keep them if fallback path uses them). Remove `from bbj_rag.config import Settings` if the endpoint no longer instantiates Settings directly.

5. **Keep the Ollama check unchanged** -- it uses httpx.AsyncClient which is already async and correct. The OLLAMA_HOST env var reading is fine.

6. **Import Request**: `from fastapi import APIRouter, Request`
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run python -c "from bbj_rag.health import router; print('health imports OK')"` to confirm imports. Run `uv run python -c "from bbj_rag.app import app; routes = {r.path: r.methods for r in app.routes if hasattr(r, 'methods')}; assert '/health' in routes; print('health route OK')"` to confirm health endpoint still registered. Run `uv run pytest tests/ -x -q` to ensure nothing is broken.
  </verify>
  <done>
/health uses pool from app.state for database connectivity check. Returns three-tier status: healthy (200), degraded (503), unhealthy (503). No standalone psycopg.connect() calls in the health check path. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "from bbj_rag.api.schemas import StatsResponse; s = StatsResponse(total_chunks=100, by_source={'flare': 50}, by_generation={'dwc': 30}); print(s.model_dump_json())"` -- StatsResponse serializes correctly
2. `uv run python -c "from bbj_rag.api.routes import router; paths = [r.path for r in router.routes]; assert '/search' in paths and '/stats' in paths; print('routes OK')"` -- both /search and /stats registered
3. `uv run python -c "import inspect; from bbj_rag.health import health; sig = inspect.signature(health); assert 'request' in sig.parameters; print('health accepts request')"` -- health endpoint accepts Request for pool access
4. `uv run pytest tests/ -x -q` -- all existing tests pass
</verification>

<success_criteria>
- GET /stats returns JSON with total_chunks, by_source (doc_type counts), by_generation (unnested counts)
- /search generation parameter normalizes hyphens to underscores before filtering
- /health uses connection pool (not standalone connections) for database check
- /health returns healthy (200) / degraded (503) / unhealthy (503) based on component status
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/22-rest-retrieval-api/22-02-SUMMARY.md`
</output>
