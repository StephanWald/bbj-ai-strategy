---
phase: 22-rest-retrieval-api
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rag-ingestion/pyproject.toml
  - rag-ingestion/src/bbj_rag/search.py
  - rag-ingestion/src/bbj_rag/app.py
  - rag-ingestion/src/bbj_rag/api/__init__.py
  - rag-ingestion/src/bbj_rag/api/deps.py
  - rag-ingestion/src/bbj_rag/api/schemas.py
  - rag-ingestion/src/bbj_rag/api/routes.py
autonomous: true

must_haves:
  truths:
    - "POST /search with {\"query\": \"BBjGrid\"} returns JSON with results array containing content, title, source_url, doc_type, generations, context_header, deprecated, score"
    - "POST /search with {\"query\": \"BBjGrid\", \"limit\": 5} returns at most 5 results"
    - "POST /search with empty query returns 422 validation error"
    - "AsyncConnectionPool is initialized in lifespan and properly closed on shutdown"
    - "Ollama embedding model is warmed up during startup"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/search.py"
      provides: "Extended SearchResult with context_header/deprecated + async_hybrid_search function"
      contains: "async_hybrid_search"
    - path: "rag-ingestion/src/bbj_rag/api/routes.py"
      provides: "POST /search endpoint"
      contains: "async def search"
    - path: "rag-ingestion/src/bbj_rag/api/schemas.py"
      provides: "SearchRequest, SearchResultItem, SearchResponse Pydantic models"
      contains: "class SearchRequest"
    - path: "rag-ingestion/src/bbj_rag/api/deps.py"
      provides: "get_conn and get_embedder dependency injection"
      contains: "async def get_conn"
    - path: "rag-ingestion/src/bbj_rag/app.py"
      provides: "AsyncConnectionPool + OllamaAsyncClient in lifespan"
      contains: "AsyncConnectionPool"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/app.py"
      to: "app.state.pool"
      via: "lifespan initializes AsyncConnectionPool and stores on app.state"
      pattern: "app\\.state\\.pool"
    - from: "rag-ingestion/src/bbj_rag/api/deps.py"
      to: "app.state.pool"
      via: "get_conn yields connection from pool via request.app.state"
      pattern: "request\\.app\\.state\\.pool"
    - from: "rag-ingestion/src/bbj_rag/api/routes.py"
      to: "rag-ingestion/src/bbj_rag/search.py"
      via: "search endpoint calls async_hybrid_search"
      pattern: "async_hybrid_search"
---

<objective>
Create the /search endpoint with async connection pooling, query embedding, and hybrid search over the ingested BBj documentation corpus.

Purpose: This is the core retrieval capability -- the reason the entire RAG pipeline exists. The /search endpoint is the primary interface for both curl consumers and the upcoming MCP server (Phase 23).

Output: A working POST /search endpoint that accepts a query, embeds it via Ollama, runs hybrid RRF search against pgvector, and returns ranked documentation chunks with all required fields.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-rest-retrieval-api/22-CONTEXT.md
@.planning/phases/22-rest-retrieval-api/22-RESEARCH.md
@rag-ingestion/src/bbj_rag/search.py
@rag-ingestion/src/bbj_rag/app.py
@rag-ingestion/src/bbj_rag/config.py
@rag-ingestion/src/bbj_rag/embedder.py
@rag-ingestion/src/bbj_rag/db.py
@rag-ingestion/src/bbj_rag/health.py
@rag-ingestion/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend search.py with missing fields and async hybrid search</name>
  <files>
    rag-ingestion/src/bbj_rag/search.py
    rag-ingestion/pyproject.toml
  </files>
  <action>
**pyproject.toml:** Change the psycopg dependency from `"psycopg[binary]>=3.3,<4"` to `"psycopg[binary,pool]>=3.3,<4"` to add the psycopg-pool extra. Then run `cd rag-ingestion && uv sync` to install the new dependency.

**search.py:** Make these targeted extensions (do NOT break existing sync functions -- the ingestion pipeline still uses them):

1. **Extend `SearchResult` dataclass** -- Add two new fields after `generations`:
   - `context_header: str` (before score)
   - `deprecated: bool` (before score)
   Field order becomes: id, source_url, title, content, doc_type, generations, context_header, deprecated, score

2. **Update `_rows_to_results`** -- Add `context_header=str(row[6])` and `deprecated=bool(row[7])`, shift `score` to `row[8]`. The function maps positional row indexes to SearchResult fields, so the new columns must be reflected.

3. **Update ALL three SELECT column lists** in `dense_search`, `bm25_search`, and `hybrid_search`:
   - Current: `SELECT id, source_url, title, content, doc_type, generations, [score_expr]`
   - New: `SELECT id, source_url, title, content, doc_type, generations, context_header, deprecated, [score_expr]`
   - For `hybrid_search`, also update the GROUP BY clause to include `context_header, deprecated`
   - For the sub-queries in `hybrid_search`, add `context_header, deprecated` to both the dense and BM25 inner SELECTs

4. **Add `async_hybrid_search` function** -- Create a new async function alongside the existing sync `hybrid_search`. It should:
   - Accept `conn: psycopg.AsyncConnection[object]` (note: `AsyncConnection` from `psycopg`)
   - Have the same parameters: `query_embedding`, `query_text`, `limit`, `generation_filter`
   - Use identical SQL string construction as `hybrid_search` (copy the SQL logic)
   - Execute with `async with conn.cursor() as cur:`, `await cur.execute(sql, ...)`, `rows = await cur.fetchall()`
   - Return `_rows_to_results(rows)` (same converter function)
   - Import `psycopg.AsyncConnection` -- note psycopg v3 exports AsyncConnection from the main `psycopg` module

5. **Update `__all__`** to include `async_hybrid_search`.

Important: The existing sync functions MUST continue working unchanged (they're used by the ingestion pipeline and test suite). The only changes to them are the additional SELECT columns and GROUP BY fields.
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv sync` to install psycopg-pool. Then run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run python -c "from bbj_rag.search import SearchResult, async_hybrid_search; print('OK')"` to confirm imports work. Run `uv run python -c "from psycopg_pool import AsyncConnectionPool; print('pool OK')"` to confirm psycopg-pool installed. Run existing tests: `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/ -x -q` -- all existing tests must still pass (the sync functions should be backward compatible since the SQL changes add columns that the _rows_to_results converter handles).
  </verify>
  <done>
SearchResult has context_header and deprecated fields. All three search functions SELECT these columns. async_hybrid_search exists and imports cleanly. psycopg-pool is installed. Existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create API subpackage with /search endpoint and extend app.py lifespan</name>
  <files>
    rag-ingestion/src/bbj_rag/api/__init__.py
    rag-ingestion/src/bbj_rag/api/deps.py
    rag-ingestion/src/bbj_rag/api/schemas.py
    rag-ingestion/src/bbj_rag/api/routes.py
    rag-ingestion/src/bbj_rag/app.py
  </files>
  <action>
**Create `api/__init__.py`:** Empty file (package marker).

**Create `api/schemas.py`:** Pydantic response models:

```python
from pydantic import BaseModel, Field

class SearchRequest(BaseModel):
    query: str = Field(..., min_length=1, description="Search query text")
    generation: str | None = Field(default=None, description="Filter by BBj generation tag (e.g. dwc, bbj_gui)")
    limit: int = Field(default=10, ge=1, le=50, description="Maximum number of results to return")

class SearchResultItem(BaseModel):
    content: str
    title: str
    source_url: str
    doc_type: str
    generations: list[str]
    context_header: str
    deprecated: bool
    score: float

class SearchResponse(BaseModel):
    query: str
    results: list[SearchResultItem]
    count: int
```

**Create `api/deps.py`:** Dependency injection functions:

- `async def get_conn(request: Request) -> AsyncIterator[AsyncConnection]` -- yields a connection from `request.app.state.pool` using `async with pool.connection() as conn: yield conn`
- `def get_settings(request: Request) -> Settings` -- returns `request.app.state.settings`
- `def get_ollama_client(request: Request) -> OllamaAsyncClient` -- returns `request.app.state.ollama_client`

Use proper type imports: `from psycopg import AsyncConnection`, `from ollama import AsyncClient as OllamaAsyncClient`, `from fastapi import Request`.

**Create `api/routes.py`:** APIRouter with the /search endpoint:

```python
router = APIRouter()

@router.post("/search", response_model=SearchResponse)
async def search(
    body: SearchRequest,
    conn: AsyncConnection = Depends(get_conn),
    ollama_client: OllamaAsyncClient = Depends(get_ollama_client),
    settings: Settings = Depends(get_settings),
) -> SearchResponse:
```

The handler should:
1. Normalize generation filter: if `body.generation` is not None, replace `-` with `_` (e.g. `bbj-gui` -> `bbj_gui`)
2. Embed the query using `await ollama_client.embed(model=settings.embedding_model, input=body.query)` -- extract the embedding from `response.embeddings[0]`. Wrap in try/except and raise `HTTPException(status_code=503, detail=f"Ollama embedding failed: {exc}")` on failure.
3. Call `await async_hybrid_search(conn=conn, query_embedding=embedding, query_text=body.query, limit=body.limit, generation_filter=gen_filter)`
4. Convert results to SearchResponse: `SearchResponse(query=body.query, results=[SearchResultItem(**vars(r)) for r in results], count=len(results))` -- note: use `vars(r)` or `r.__dict__` to convert dataclass to dict, but exclude `id` since SearchResultItem doesn't have it. Better: build each SearchResultItem explicitly from the SearchResult fields (content, title, source_url, doc_type, generations, context_header, deprecated, score).

**Extend `app.py` lifespan:**

After the existing schema application block, add pool initialization:

1. Import `AsyncConnectionPool` from `psycopg_pool`, `register_vector_async` from `pgvector.psycopg`, `AsyncClient as OllamaAsyncClient` from `ollama`
2. Build conninfo string: `f"host={settings.db_host} port={settings.db_port} dbname={settings.db_name} user={settings.db_user} password={settings.db_password}"`
3. Create pool: `AsyncConnectionPool(conninfo=conninfo, min_size=2, max_size=5, open=False, configure=register_vector_async)`
4. `await pool.open()`
5. Create `OllamaAsyncClient()` -- no arguments needed, it reads OLLAMA_HOST from env
6. Fire warm-up embedding: `try: await ollama_client.embed(model=settings.embedding_model, input="warm-up") except Exception: logger.warning("Embedding warm-up failed (non-fatal)")`
7. Store on app.state: `app.state.pool = pool`, `app.state.settings = settings`, `app.state.ollama_client = ollama_client`
8. After `yield`, add cleanup: `await pool.close()`

Also:
- Import and include the api router: `from bbj_rag.api.routes import router as api_router` and `app.include_router(api_router)`
- Keep the existing health_router inclusion

Important: The existing startup logic (validate_environment, log_startup_summary, apply_schema) should remain. The pool initialization happens AFTER schema application (schema needs to exist before pool connections can be used). Move the `settings = Settings()` call to before schema application so it can be reused for pool conninfo.
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run python -c "from bbj_rag.api.routes import router; from bbj_rag.api.schemas import SearchRequest, SearchResponse, SearchResultItem; from bbj_rag.api.deps import get_conn, get_settings, get_ollama_client; print('API imports OK')"`. Run `uv run python -c "from bbj_rag.app import app; print(app.title, [r.path for r in app.routes])"` to confirm routes are registered. Run existing tests: `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/ -x -q` to ensure nothing is broken.
  </verify>
  <done>
The api/ subpackage exists with schemas.py, deps.py, and routes.py. The /search endpoint is registered on the FastAPI app. app.py lifespan initializes AsyncConnectionPool with register_vector_async configure callback, creates OllamaAsyncClient, warms up the embedding model, stores all on app.state, and closes the pool on shutdown. All existing tests pass.
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "from psycopg_pool import AsyncConnectionPool; print('pool OK')"` -- psycopg-pool installed
2. `uv run python -c "from bbj_rag.search import SearchResult; r = SearchResult(id=1, source_url='u', title='t', content='c', doc_type='d', generations=['g'], context_header='h', deprecated=False, score=0.5); print(r.context_header, r.deprecated)"` -- SearchResult has new fields
3. `uv run python -c "from bbj_rag.search import async_hybrid_search; print('async OK')"` -- async function exists
4. `uv run python -c "from bbj_rag.app import app; paths = [r.path for r in app.routes]; assert '/search' in paths; print('search route OK')"` -- /search registered
5. `uv run pytest tests/ -x -q` -- all existing tests pass
</verification>

<success_criteria>
- POST /search endpoint exists and accepts SearchRequest body with query (required), generation (optional), limit (optional, default 10, max 50)
- Response model includes content, title, source_url, doc_type, generations, context_header, deprecated, score
- AsyncConnectionPool initialized in lifespan with register_vector_async configure callback
- OllamaAsyncClient used for non-blocking query embedding
- Embedding model warm-up fires during startup
- Pool properly closed on shutdown
- All existing tests pass (sync search functions and ingestion pipeline unaffected)
</success_criteria>

<output>
After completion, create `.planning/phases/22-rest-retrieval-api/22-01-SUMMARY.md`
</output>
