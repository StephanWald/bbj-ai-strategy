---
phase: 24-end-to-end-validation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - rag-ingestion/VALIDATION.md
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "PDF source (GuideToGuiProgrammingInBBj.pdf) has chunks in the database after re-ingestion"
    - "curl localhost:10800/stats shows non-zero chunk count for pdf doc_type or pdf-prefixed source"
    - "All 6 logical sources now have chunks in the database"
    - "Re-running validation script shows improved pass count (PDF no longer missing from cross-source table)"
  artifacts:
    - path: "rag-ingestion/VALIDATION.md"
      provides: "Updated validation report with PDF source present"
  key_links:
    - from: "rag-ingestion/sources.toml"
      to: "rag-ingestion/docker-compose.yml"
      via: "sources.toml paths=['bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf'] + DATA_DIR=/data resolves to /data/bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf which is inside the existing volume mount"
      pattern: "bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf"
    - from: "rag-ingestion/src/bbj_rag/ingest_all.py"
      to: "rag-ingestion/src/bbj_rag/parsers/pdf.py"
      via: "_create_parser_for_source instantiates PdfParser(pdf_path=data_dir / source.paths[0])"
      pattern: "PdfParser\\(pdf_path="
---

<objective>
Diagnose and fix why PDF ingestion produced 0 chunks despite the file being accessible inside the Docker container. The bbj-ai-strategy directory is already volume-mounted at `/data/bbj-ai-strategy:ro`, and sources.toml `paths = ["bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf"]` with `DATA_DIR=/data` resolves to `/data/bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf` -- which should exist. The root cause is NOT a missing volume mount. After diagnosing and fixing the actual issue, re-ingest and re-validate.

Purpose: Close the one verification gap (4/5 -> 5/5 truths) so the v1.4 milestone is fully validated with all 6 BBj documentation sources ingested.
Output: PDF chunks in database, refreshed VALIDATION.md report. Possible code fix depending on diagnosis.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-end-to-end-validation/24-01-SUMMARY.md
@.planning/phases/24-end-to-end-validation/24-VERIFICATION.md
@rag-ingestion/docker-compose.yml
@rag-ingestion/sources.toml
@rag-ingestion/src/bbj_rag/source_config.py
@rag-ingestion/src/bbj_rag/ingest_all.py
@rag-ingestion/src/bbj_rag/parsers/pdf.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Diagnose PDF ingestion failure and fix root cause</name>
  <files>rag-ingestion/src/bbj_rag/source_config.py, rag-ingestion/src/bbj_rag/parsers/pdf.py, rag-ingestion/src/bbj_rag/ingest_all.py</files>
  <action>
The PDF file IS volume-mounted. The bbj-ai-strategy repo is mounted at `/data/bbj-ai-strategy` (docker-compose.yml line 50). The sources.toml path `bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf` with `DATA_DIR=/data` resolves to `/data/bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf`. Do NOT add a new volume mount or change docker-compose.yml.

**Step 1: Verify the file is accessible inside the container:**
```bash
docker exec rag-ingestion-app-1 ls -lh /data/bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf
```
If this succeeds, the volume mount is working and the issue is downstream.

**Step 2: Test path resolution in source_config.py:**
```bash
docker exec rag-ingestion-app-1 python3 -c "
from pathlib import Path
data_dir = Path('/data')
rel_path = 'bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf'
full = data_dir / rel_path
print(f'Resolved: {full}')
print(f'Exists: {full.exists()}')
print(f'Is file: {full.is_file()}')
"
```

**Step 3: Test validate_sources specifically for PDF:**
```bash
docker exec rag-ingestion-app-1 python3 -c "
from bbj_rag.source_config import load_sources_config, resolve_data_dir, validate_sources
from pathlib import Path
cfg = load_sources_config(Path('sources.toml'))
data_dir = resolve_data_dir(cfg)
pdf_sources = [s for s in cfg.sources if s.parser == 'pdf']
errors = validate_sources(pdf_sources, data_dir)
print(f'Data dir: {data_dir}')
print(f'PDF paths: {pdf_sources[0].paths}')
print(f'Validation errors: {errors}')
"
```
If validation fails here, the resolved path doesn't exist inside the container -- investigate why (permissions, mount timing, etc.).

**Step 4: Test the --source pdf flag matching:**
```bash
docker exec rag-ingestion-app-1 python3 -c "
from bbj_rag.source_config import load_sources_config
from pathlib import Path
cfg = load_sources_config(Path('sources.toml'))
pdf = [s for s in cfg.sources if s.name == 'pdf']
print(f'Found {len(pdf)} source(s) named pdf')
print(f'Enabled: {pdf[0].enabled if pdf else None}')
print(f'Parser: {pdf[0].parser if pdf else None}')
"
```

**Step 5: Try running ingestion with verbose output to see what happens:**
```bash
docker exec rag-ingestion-app-1 uv run bbj-ingest-all --source pdf --clean -v 2>&1
```
Watch the output carefully:
- Does validate_sources pass? (Look for "Validation OK")
- Does the parser produce documents? (Look for "PDF ... extracted N sections")
- Does run_pipeline report chunks? (Look for "Done: N docs, N chunks")
- Is there an exception? (Look for "FAILED")

**Step 6: Based on diagnosis, fix the root cause:**

Likely scenarios and fixes:

a) **validate_sources fails (file not found in container):** Check if the container was rebuilt since the PDF was added. Try `docker compose up -d --build app` to rebuild. The volume mount is read-only -- verify the host file exists at the expected path.

b) **PdfParser.parse() produces 0 sections:** The `_split_sections()` function requires markdown headings (`#`, `##`, `###`). If pymupdf4llm doesn't extract headings from this particular PDF, sections will be empty. Fix: Add a fallback in PdfParser.parse() that yields the entire document as a single Document if `_split_sections` returns empty -- e.g., after line 177:
   ```python
   if not sections:
       logger.warning("PDF %s: no heading sections found, using full text as single doc", pdf_filename)
       sections = [(pdf_filename.replace(".pdf", ""), full_markdown)]
   ```

c) **pymupdf fails to open the file:** Could be a permissions issue with the `:ro` mount. Check the error in verbose output. If the file is corrupt or unreadable, the exception handler in ingest_all.py line 413 would catch it.

d) **run_pipeline produces 0 chunks from valid documents:** Unlikely but check if chunk_size/overlap settings filter out all content.

e) **The source was never run in the original ingestion:** Check if `--source pdf` was included. The phase 23.1-03 summary logged "0 docs, 0 chunks" with "OK" status, meaning the parser ran but found nothing -- this points to scenario (b).

Apply the appropriate fix. Do NOT modify docker-compose.yml or the sources.toml paths -- the current configuration resolves correctly.

After fixing, re-ingest:
```bash
docker exec rag-ingestion-app-1 uv run bbj-ingest-all --source pdf --clean -v 2>&1
```

Verify chunks were created:
```bash
docker exec rag-ingestion-db-1 psql -U bbj -d bbj_rag -c "SELECT COUNT(*) FROM chunks WHERE source_url LIKE 'pdf://%';"
```
The count must be > 0.
  </action>
  <verify>
1. `docker exec rag-ingestion-app-1 ls -lh /data/bbj-ai-strategy/GuideToGuiProgrammingInBBj.pdf` succeeds (file exists in container)
2. `docker exec rag-ingestion-app-1 uv run bbj-ingest-all --source pdf --clean -v` completes with non-zero docs and chunks
3. `docker exec rag-ingestion-db-1 psql -U bbj -d bbj_rag -c "SELECT COUNT(*) FROM chunks WHERE source_url LIKE 'pdf://%';"` returns count > 0
4. `curl -s http://localhost:10800/stats` shows total_chunks > 50,392
  </verify>
  <done>Root cause identified and fixed. PDF source has non-zero chunks in the database. The ingestion pipeline correctly reads the file from the existing volume mount at /data/bbj-ai-strategy/.</done>
</task>

<task type="auto">
  <name>Task 2: Re-run validation and update report</name>
  <files>rag-ingestion/VALIDATION.md</files>
  <action>
Re-run the existing validation script to regenerate VALIDATION.md with updated results that include the PDF source:

```bash
cd rag-ingestion && uv run python scripts/validate_e2e.py
```

This will:
- Re-query all 14 REST API queries (6 source-targeted + 7 topic-based + 1 generation-filtered)
- Re-query all 3 MCP queries
- Regenerate the cross-source summary table
- Overwrite VALIDATION.md with fresh results

After the script completes, check the output:
1. The cross-source summary table should now show "Yes" for the PDF row (previously "No")
2. The source-targeted query for PDF ("customer information program BBj GUI example") may now pass if pdf:// chunks rank in top results
3. The overall pass count should be >= 13/17 (may improve if PDF chunks help targeted queries)
4. The corpus stats section should show a higher total_chunks count

If the validation script fails for any reason (Docker not running, Ollama down), check prerequisites:
- `docker compose ps` -- both containers healthy
- `curl http://localhost:10800/health` -- returns {"status":"healthy"}
- Ollama running on host with `OLLAMA_HOST=0.0.0.0:11434`
  </action>
  <verify>
1. `rag-ingestion/VALIDATION.md` exists and contains a "Generated:" timestamp newer than the previous report
2. The Cross-Source Summary table shows PDF row with "Yes" in the "Found in Results" column, OR the corpus stats show pdf-related chunks (confirming PDF is in the database even if it doesn't rank in top-5 for queries)
3. The corpus stats total_chunks is greater than 50,392
  </verify>
  <done>VALIDATION.md regenerated with PDF source included in the corpus. The cross-source summary reflects all 6 sources having chunks in the database.</done>
</task>

</tasks>

<verification>
1. `docker exec rag-ingestion-db-1 psql -U bbj -d bbj_rag -c "SELECT COUNT(*) FROM chunks WHERE source_url LIKE 'pdf://%';"` returns count > 0
2. `curl -s http://localhost:10800/stats` shows increased total_chunks with pdf entries
3. `rag-ingestion/VALIDATION.md` has been regenerated with updated timestamp
4. The verification gap (truth #4: "All 6 logical sources have chunks in the database") is now closable
</verification>

<success_criteria>
- Root cause of 0 PDF chunks diagnosed and documented
- PDF source has chunks in the database (was 0, now > 0)
- No unnecessary changes to docker-compose.yml or sources.toml (existing config resolves correctly)
- VALIDATION.md regenerated with all 6 sources represented in corpus stats
- Total chunk count > 50,392 (previous count before PDF)
</success_criteria>

<output>
After completion, create `.planning/phases/24-end-to-end-validation/24-02-SUMMARY.md`
</output>
