---
phase: 29-ingestion-performance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rag-ingestion/src/bbj_rag/embedder.py
  - rag-ingestion/src/bbj_rag/config.py
autonomous: true

must_haves:
  truths:
    - "AsyncOllamaEmbedder can embed batches using httpx.AsyncClient"
    - "HTTP connection is reused across multiple embed_batch calls"
    - "Configuration fields exist for parallel ingestion settings"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/embedder.py"
      provides: "AsyncOllamaEmbedder class with persistent connection"
      contains: "class AsyncOllamaEmbedder"
    - path: "rag-ingestion/src/bbj_rag/config.py"
      provides: "Parallel ingestion configuration fields"
      contains: "ingest_workers"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/embedder.py"
      to: "httpx.AsyncClient"
      via: "connection pooling for Ollama HTTP calls"
      pattern: "AsyncClient.*limits"
---

<objective>
Add async embedding capability with persistent HTTP connections to Ollama.

Purpose: Enable efficient concurrent embedding by creating an async embedder that reuses HTTP connections across batches, eliminating per-batch connection setup overhead.

Output: AsyncOllamaEmbedder class with httpx.AsyncClient connection pooling, plus config fields for parallel ingestion settings.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-ingestion-performance/29-CONTEXT.md
@rag-ingestion/src/bbj_rag/embedder.py
@rag-ingestion/src/bbj_rag/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AsyncOllamaEmbedder with persistent connections</name>
  <files>rag-ingestion/src/bbj_rag/embedder.py</files>
  <action>
Add a new AsyncOllamaEmbedder class that:

1. Uses httpx.AsyncClient with connection pooling (httpx.Limits for max_connections)
2. Implements async embed_batch() method that calls Ollama's /api/embed endpoint directly
3. Manages client lifecycle with async context manager pattern (__aenter__/__aexit__)
4. Reuses the same AsyncClient instance across all embed_batch calls within a session

Implementation details:
- Ollama embed endpoint: POST http://localhost:11434/api/embed with JSON body {"model": model, "input": texts}
- Response JSON has "embeddings" array
- Use httpx.Limits(max_connections=10, max_keepalive_connections=5) for connection pooling
- Add host parameter defaulting to OLLAMA_HOST env var or "http://localhost:11434"
- Keep the existing sync OllamaEmbedder and OpenAIEmbedder unchanged (backward compatibility)

Add factory function create_async_embedder(settings) that returns AsyncOllamaEmbedder.

Update __all__ to export AsyncOllamaEmbedder and create_async_embedder.
  </action>
  <verify>
Run: cd rag-ingestion && uv run python -c "
from bbj_rag.embedder import AsyncOllamaEmbedder
import asyncio

async def test():
    async with AsyncOllamaEmbedder() as embedder:
        result = await embedder.embed_batch(['test'])
        print(f'Embedding dimensions: {len(result[0])}')
        print('Connection reuse test...')
        result2 = await embedder.embed_batch(['test2'])
        print(f'Second batch dimensions: {len(result2[0])}')
        print('OK')

asyncio.run(test())
"
Should print dimensions (1024) for both batches without connection errors.
  </verify>
  <done>AsyncOllamaEmbedder class exists, uses httpx.AsyncClient with connection limits, and can embed multiple batches reusing the same connection pool.</done>
</task>

<task type="auto">
  <name>Task 2: Add parallel ingestion configuration fields</name>
  <files>rag-ingestion/src/bbj_rag/config.py</files>
  <action>
Add new configuration fields to the Settings class for parallel ingestion:

1. ingest_workers: int = Field(default=4)
   - Number of concurrent embedding workers
   - Env var: BBJ_RAG_INGEST_WORKERS

2. ingest_max_workers: int = Field(default=8)
   - Maximum allowed workers (cap for --workers flag)
   - Env var: BBJ_RAG_INGEST_MAX_WORKERS

3. ingest_batch_retries: int = Field(default=3)
   - Number of retry attempts for failed batches
   - Env var: BBJ_RAG_INGEST_BATCH_RETRIES

4. ingest_failure_log: str = Field(default=".ingestion-failures.json")
   - Path to failure log file for --retry-failed
   - Env var: BBJ_RAG_INGEST_FAILURE_LOG

5. ollama_host: str = Field(default="http://localhost:11434")
   - Ollama server URL for async embedder
   - Env var: BBJ_RAG_OLLAMA_HOST (also checks OLLAMA_HOST for compatibility)

For ollama_host, implement a validator that checks OLLAMA_HOST env var as fallback if BBJ_RAG_OLLAMA_HOST is not set.
  </action>
  <verify>
Run: cd rag-ingestion && uv run python -c "
from bbj_rag.config import Settings
s = Settings()
print(f'ingest_workers: {s.ingest_workers}')
print(f'ingest_max_workers: {s.ingest_max_workers}')
print(f'ingest_batch_retries: {s.ingest_batch_retries}')
print(f'ingest_failure_log: {s.ingest_failure_log}')
print(f'ollama_host: {s.ollama_host}')
"
Should print all 5 fields with their default values.
  </verify>
  <done>Settings class has ingest_workers=4, ingest_max_workers=8, ingest_batch_retries=3, ingest_failure_log, and ollama_host fields with appropriate defaults and env var support.</done>
</task>

</tasks>

<verification>
1. AsyncOllamaEmbedder can be instantiated and used as async context manager
2. embed_batch returns correct-dimension vectors (1024 for qwen3-embedding:0.6b)
3. Multiple embed_batch calls reuse the same connection pool (no connection refused errors)
4. All new config fields exist with correct defaults
5. Existing tests pass: cd rag-ingestion && uv run pytest tests/test_embedder.py tests/test_config.py -v
</verification>

<success_criteria>
- AsyncOllamaEmbedder class with httpx.AsyncClient connection pooling
- create_async_embedder factory function
- 5 new config fields for parallel ingestion
- Backward compatibility maintained (sync embedder unchanged)
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/29-ingestion-performance/29-01-SUMMARY.md`
</output>
