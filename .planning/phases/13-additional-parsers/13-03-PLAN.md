---
phase: 13-additional-parsers
plan: 03
type: execute
wave: 2
depends_on: ["13-01", "13-02"]
files_modified:
  - rag-ingestion/src/bbj_rag/parsers/mdx.py
  - rag-ingestion/src/bbj_rag/pipeline.py
  - rag-ingestion/src/bbj_rag/cli.py
  - rag-ingestion/src/bbj_rag/config.py
  - rag-ingestion/tests/test_mdx_parser.py
  - rag-ingestion/tests/test_pipeline.py
autonomous: true

must_haves:
  truths:
    - "MDX parser extracts content from DWC-Course .md/.mdx files with frontmatter metadata parsed and JSX stripped"
    - "All DWC-Course content is uniformly tagged as dwc generation"
    - "Pipeline skips Flare-specific intelligence for non-Flare parsers that pre-populate generations and doc_type"
    - "CLI supports all five new sources via --source flag"
    - "Config has settings for PDF path, source dirs, WordPress URLs, and DWC-Course path"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/parsers/mdx.py"
      provides: "MdxParser implementing DocumentParser protocol"
      contains: "class MdxParser"
    - path: "rag-ingestion/src/bbj_rag/pipeline.py"
      provides: "Updated pipeline with intelligence bypass for pre-populated docs"
      contains: "doc.doc_type"
    - path: "rag-ingestion/src/bbj_rag/cli.py"
      provides: "CLI with all source types: flare, pdf, advantage, kb, mdx, bbj-source"
      contains: "pdf.*advantage.*kb.*mdx.*bbj-source"
    - path: "rag-ingestion/src/bbj_rag/config.py"
      provides: "Settings for all parser source paths"
      contains: "pdf_source_path|mdx_source_path|bbj_source_dirs"
    - path: "rag-ingestion/tests/test_mdx_parser.py"
      provides: "Unit tests for MDX parser"
    - path: "rag-ingestion/tests/test_pipeline.py"
      provides: "Tests for pipeline intelligence bypass"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/cli.py"
      to: "all parser modules"
      via: "_create_parser switch on source name"
      pattern: "source == .pdf.|source == .advantage.|source == .kb.|source == .mdx.|source == .bbj-source."
    - from: "rag-ingestion/src/bbj_rag/pipeline.py"
      to: "intelligence bypass"
      via: "guard checking if doc already has non-placeholder values"
      pattern: "doc\\.doc_type|_apply_intelligence"
    - from: "rag-ingestion/src/bbj_rag/parsers/mdx.py"
      to: "bbj_rag.models.Document"
      via: "yield Document(...)"
      pattern: "yield Document\\("
---

<objective>
Implement the Docusaurus MDX parser for DWC-Course content, then wire ALL five new parsers into the pipeline and CLI. This plan creates the MDX parser and handles all integration work: pipeline intelligence bypass, CLI source expansion, and config settings.

Purpose: The MDX parser covers PARSE-07 (DWC-Course). The integration work connects all five new parsers (PDF, BBj source, Advantage, KB, MDX) to the existing pipeline machinery, making them runnable via `bbj-rag ingest --source <name>`.

Output: MDX parser module with tests, updated pipeline with intelligence bypass, expanded CLI with all sources, and new config settings.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-additional-parsers/13-CONTEXT.md
@.planning/phases/13-additional-parsers/13-RESEARCH.md
@.planning/phases/13-additional-parsers/13-01-SUMMARY.md
@.planning/phases/13-additional-parsers/13-02-SUMMARY.md

# Files to modify
@rag-ingestion/src/bbj_rag/pipeline.py
@rag-ingestion/src/bbj_rag/cli.py
@rag-ingestion/src/bbj_rag/config.py
@rag-ingestion/src/bbj_rag/parsers/__init__.py
@rag-ingestion/src/bbj_rag/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: MDX parser and pipeline integration</name>
  <files>
    rag-ingestion/src/bbj_rag/parsers/mdx.py
    rag-ingestion/src/bbj_rag/pipeline.py
    rag-ingestion/src/bbj_rag/cli.py
    rag-ingestion/src/bbj_rag/config.py
  </files>
  <action>
**Create `parsers/mdx.py` -- MdxParser class:**

Implement `MdxParser` with `__init__(self, docs_dir: Path)` and `parse() -> Iterator[Document]`.

Key implementation details:
- Use `python-frontmatter` to parse YAML frontmatter from each file
- Iterate over `.md` and `.mdx` files recursively in `docs_dir` using `sorted(docs_dir.rglob("*.md"))` and `sorted(docs_dir.rglob("*.mdx"))`
- For each file:
  1. Load with `frontmatter.load(str(path))`
  2. Extract metadata: `title` from frontmatter (fall back to first `# ` heading, then filename stem), `sidebar_position` for ordering
  3. Strip JSX from content using two-pass approach:
     - Remove import statements: `re.sub(r"^import\s+.+$", "", content, flags=re.MULTILINE)`
     - Remove self-closing JSX: `re.sub(r"<[A-Z][A-Za-z]*\s*/>", "", content)` (e.g., `<Hero />`)
     - Strip JSX wrapper tags but keep inner text: `re.sub(r"<[A-Z][A-Za-z]*[^>]*>", "", content)` and `re.sub(r"</[A-Z][A-Za-z]*>", "", content)`
     - Strip HTML divs with className: `re.sub(r'<div\s+className="[^"]*"[^>]*>', "", content)` and `re.sub(r"</div>", "", content)`
     - Collapse excessive blank lines: `re.sub(r"\n{3,}", "\n\n", content)`
  4. Skip files with empty content after stripping
  5. Keep Mermaid code blocks as-is (they are text content, no special handling needed since they are inside regular markdown fenced code blocks)
  6. Yield Document:
     - `source_url`: `"dwc-course://{relative_path}"` (relative to docs_dir, e.g., `"dwc-course://01-introduction/index.md"`)
     - `title`: from frontmatter or heading
     - `doc_type`: `"tutorial"` (DWC-Course is tutorial content)
     - `content`: cleaned markdown
     - `generations`: `["dwc"]` (user decision: ALL DWC-Course content uniform dwc tag)
     - `context_header`: `"DWC Course > {chapter_dir} > {title}"` where chapter_dir is derived from the parent directory name (e.g., "01-introduction" -> "Introduction")
     - `metadata`: `{"source": "dwc_course", "sidebar_position": str(pos)}` (if sidebar_position exists in frontmatter)
     - `deprecated`: False
- Log: total files found, files processed, files skipped

**Update `pipeline.py` -- intelligence bypass for non-Flare parsers:**

The current `run_pipeline()` always calls `_apply_intelligence()` which assumes Flare content paths (flare:// URLs, condition metadata). New parsers pre-populate `generations`, `doc_type`, `context_header`, and `deprecated` on their Documents.

Add a guard in the `run_pipeline()` main loop. Replace the unconditional `_apply_intelligence()` call with:

```python
# Check if parser already populated intelligence fields.
# Flare parser leaves doc_type as empty string; non-Flare parsers set it.
if doc.doc_type and doc.doc_type != "web_crawl":
    # Parser pre-populated intelligence -- use as-is.
    generations = doc.generations
    deprecated = doc.deprecated
    doc_type = doc.doc_type
    context_header = doc.context_header
else:
    # Flare/web_crawl docs need intelligence enrichment.
    generations, deprecated, doc_type, context_header = _apply_intelligence(
        doc.source_url, doc.content, doc.metadata
    )
```

Then update the `doc = doc.model_copy(update={...})` block to use these variables (it already does this, just ensure `context_header` is included in the update dict if it is not already).

IMPORTANT: The existing Flare parser yields Documents with `doc_type=""` (empty string) and `generations=["bbj"]` (placeholder). The web crawl parser yields `doc_type="web_crawl"`. Both need `_apply_intelligence()`. New parsers yield specific doc_type values like "example", "concept", "article", "tutorial" -- these skip intelligence.

**Update `config.py` -- add new source settings:**

Add these fields to the Settings class:
- `pdf_source_path: str = Field(default="")` -- path to GuideToGuiProgrammingInBBj.pdf
- `mdx_source_path: str = Field(default="")` -- path to DWC-Course docs/ directory
- `bbj_source_dirs: list[str] = Field(default_factory=list)` -- list of directories containing BBj source files
- `advantage_index_url: str = Field(default="https://basis.cloud/advantage-index/")` -- Advantage index URL
- `kb_index_url: str = Field(default="https://basis.cloud/knowledge-base/")` -- Knowledge Base index URL

**Update `cli.py` -- expand source choices and _create_parser:**

1. Update the `--source` option on both `ingest` and `parse` commands: change `type=click.Choice(["flare"])` to `type=click.Choice(["flare", "pdf", "advantage", "kb", "mdx", "bbj-source"])`

2. Expand `_create_parser()` with new source branches:

```python
elif source == "pdf":
    from bbj_rag.parsers.pdf import PdfParser
    pdf_path = settings.pdf_source_path
    if not pdf_path:
        _fatal("Error: pdf_source_path not configured.\n"
               "Set BBJ_RAG_PDF_SOURCE_PATH or add to config.toml.")
    path = Path(pdf_path)
    if not path.is_file():
        _fatal(f"Error: PDF file not found: {path}")
    return PdfParser(pdf_path=path)

elif source == "advantage":
    from bbj_rag.parsers.wordpress import AdvantageParser
    return AdvantageParser(index_url=settings.advantage_index_url)

elif source == "kb":
    from bbj_rag.parsers.wordpress import KnowledgeBaseParser
    return KnowledgeBaseParser(index_url=settings.kb_index_url)

elif source == "mdx":
    from bbj_rag.parsers.mdx import MdxParser
    mdx_path = settings.mdx_source_path
    if not mdx_path:
        _fatal("Error: mdx_source_path not configured.\n"
               "Set BBJ_RAG_MDX_SOURCE_PATH or add to config.toml.")
    path = Path(mdx_path)
    if not path.is_dir():
        _fatal(f"Error: MDX docs directory not found: {path}")
    return MdxParser(docs_dir=path)

elif source == "bbj-source":
    from bbj_rag.parsers.bbj_source import BbjSourceParser
    dirs = settings.bbj_source_dirs
    if not dirs:
        _fatal("Error: bbj_source_dirs not configured.\n"
               "Set BBJ_RAG_BBJ_SOURCE_DIRS or add to config.toml.")
    source_paths = [Path(d) for d in dirs]
    for sp in source_paths:
        if not sp.is_dir():
            _fatal(f"Error: BBj source directory not found: {sp}")
    return BbjSourceParser(source_dirs=source_paths)
```

Keep lazy imports inside each branch (consistent with existing flare pattern).
  </action>
  <verify>
Run `uv run python -c "from bbj_rag.parsers.mdx import MdxParser; print('OK')"` -- imports clean.
Run `uv run ruff check src/bbj_rag/parsers/mdx.py src/bbj_rag/pipeline.py src/bbj_rag/cli.py src/bbj_rag/config.py` -- lint clean.
Run `uv run mypy src/bbj_rag/parsers/mdx.py src/bbj_rag/pipeline.py src/bbj_rag/cli.py src/bbj_rag/config.py` -- type checks pass.
Run `uv run bbj-rag --help` -- shows all source choices in help text.
  </verify>
  <done>
MdxParser extracts MDX content with frontmatter parsing and JSX stripping. Pipeline has intelligence bypass for pre-populated Documents. CLI supports all 6 sources (flare, pdf, advantage, kb, mdx, bbj-source). Config has settings for all source paths.
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for MDX parser and pipeline intelligence bypass</name>
  <files>
    rag-ingestion/tests/test_mdx_parser.py
    rag-ingestion/tests/test_pipeline.py
  </files>
  <action>
**Create `tests/test_mdx_parser.py`:**

Use `tmp_path` fixture to create temporary MDX files.

Tests to write:
1. `test_mdx_parser_implements_protocol` -- isinstance check
2. `test_mdx_parser_yields_documents` -- Create temp dir with a `.md` file with frontmatter `---\ntitle: Test\nsidebar_position: 1\n---\n# Content\nSome text`. Verify Document yielded with title "Test".
3. `test_mdx_parser_strips_imports` -- File with `import Hero from '@site/src/components/Hero'` line. Verify import line removed from content.
4. `test_mdx_parser_strips_self_closing_jsx` -- File with `<Hero />` component. Verify removed.
5. `test_mdx_parser_strips_wrapper_jsx_keeps_text` -- File with `<Link to="/foo">Click here</Link>`. Verify "Click here" preserved but Link tags removed.
6. `test_mdx_parser_preserves_mermaid` -- File with ` ```mermaid\ngraph LR\n``` `. Verify mermaid block preserved.
7. `test_mdx_parser_uses_frontmatter_title` -- Verify frontmatter title takes priority over heading.
8. `test_mdx_parser_falls_back_to_heading_title` -- File with no frontmatter title but has `# My Heading`. Verify title is "My Heading".
9. `test_mdx_parser_uniform_dwc_generation` -- All documents get `["dwc"]` generation.
10. `test_mdx_parser_doc_type_tutorial` -- All documents get `doc_type="tutorial"`.
11. `test_mdx_parser_context_header` -- Verify context_header includes "DWC Course > chapter > title".
12. `test_mdx_parser_skips_empty_files` -- File with only JSX (no text content after stripping). Verify no Document yielded.
13. `test_mdx_parser_handles_mdx_extension` -- Parser processes both `.md` and `.mdx` files.

**Create or update `tests/test_pipeline.py`:**

If test_pipeline.py does not exist, create it. If it exists, add to it.

Tests for intelligence bypass:
1. `test_pipeline_skips_intelligence_for_prepopulated_docs` -- Create a mock parser yielding Documents with `doc_type="example"` and `generations=["dwc"]`. Mock embedder and db. Run `run_pipeline()`. Verify `_apply_intelligence` was NOT called (or that the doc's generations were preserved, not overwritten).
2. `test_pipeline_applies_intelligence_for_flare_docs` -- Create a mock parser yielding Documents with `doc_type=""` (Flare pattern). Verify `_apply_intelligence` WAS called.
3. `test_pipeline_applies_intelligence_for_web_crawl_docs` -- Create a mock parser yielding Documents with `doc_type="web_crawl"`. Verify `_apply_intelligence` WAS called.

Mock strategy: For pipeline tests, mock `_apply_intelligence`, the embedder (return dummy vectors), and `bulk_insert_chunks` (return count). Focus on verifying the intelligence bypass logic, not the full pipeline.
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/test_mdx_parser.py tests/test_pipeline.py -v` -- all tests pass.
Run `uv run pytest` -- full suite passes (no regressions).
Run `uv run ruff check tests/test_mdx_parser.py tests/test_pipeline.py` for lint.
  </verify>
  <done>
13 MDX parser tests + 3 pipeline bypass tests all pass. MDX parser correctly strips JSX, preserves text content, parses frontmatter, and tags uniformly as dwc. Pipeline intelligence bypass works: pre-populated docs skip _apply_intelligence, Flare/web_crawl docs still go through it. Full test suite shows no regressions.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest` -- full suite passes (existing + all new tests from Plans 01-03)
2. `uv run ruff check src/ tests/` -- no lint errors
3. `uv run mypy src/` -- type checks pass
4. `uv run bbj-rag ingest --help` -- shows source choices: flare, pdf, advantage, kb, mdx, bbj-source
5. Pipeline correctly bypasses intelligence for non-Flare parsers
6. All five new parser classes implement DocumentParser protocol
</verification>

<success_criteria>
- MdxParser parses .md/.mdx files with frontmatter extraction and JSX stripping
- All DWC-Course content uniformly tagged ["dwc"] (user decision honored)
- Pipeline intelligence bypass works for pre-populated Documents
- CLI expanded to 6 source types with proper validation
- Config settings added for all source paths
- 16+ new tests (13 MDX + 3 pipeline) pass
- Full test suite shows no regressions across all plans
</success_criteria>

<output>
After completion, create `.planning/phases/13-additional-parsers/13-03-SUMMARY.md`
</output>
