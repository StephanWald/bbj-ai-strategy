---
phase: 13-additional-parsers
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - rag-ingestion/src/bbj_rag/parsers/wordpress.py
  - rag-ingestion/tests/test_wordpress_parser.py
autonomous: true

must_haves:
  truths:
    - "WordPress parser extracts article content from Advantage magazine pages with boilerplate stripped"
    - "WordPress parser extracts Knowledge Base content with ECKB plugin layout handled"
    - "Both parsers use web crawl approach (httpx + BeautifulSoup), not WordPress REST API"
    - "All Advantage articles ingested without topic filtering"
    - "Knowledge Base lessons extracted as flat standalone documents"
    - "All media stripped -- text content only"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/parsers/wordpress.py"
      provides: "AdvantageParser and KnowledgeBaseParser implementing DocumentParser protocol"
      contains: "class AdvantageParser"
    - path: "rag-ingestion/tests/test_wordpress_parser.py"
      provides: "Unit tests for WordPress parsers"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/parsers/wordpress.py"
      to: "bbj_rag.models.Document"
      via: "yield Document(...)"
      pattern: "yield Document\\("
    - from: "rag-ingestion/src/bbj_rag/parsers/wordpress.py"
      to: "bbj_rag.parsers.web_crawl"
      via: "reuse _html_to_markdown, _strip_chrome patterns"
      pattern: "_html_to_markdown|_strip_chrome|_find_content_root"
---

<objective>
Implement WordPress parsers for Advantage magazine articles (basis.cloud/advantage-index/) and Knowledge Base lessons (basis.cloud/knowledge-base/) using httpx + BeautifulSoup web crawl approach.

Purpose: These two parsers cover the WordPress/Advantage source (PARSE-05) and WordPress/Knowledge Base source (PARSE-06), completing the web-based content sources.

Output: One parser module with two parser classes (AdvantageParser, KnowledgeBaseParser) plus unit tests.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-additional-parsers/13-CONTEXT.md
@.planning/phases/13-additional-parsers/13-RESEARCH.md

# Existing web crawl patterns to reuse
@rag-ingestion/src/bbj_rag/parsers/web_crawl.py
@rag-ingestion/src/bbj_rag/parsers/__init__.py
@rag-ingestion/src/bbj_rag/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: WordPress parser module with Advantage and Knowledge Base parsers</name>
  <files>
    rag-ingestion/src/bbj_rag/parsers/wordpress.py
  </files>
  <action>
**Create `parsers/wordpress.py` with two parser classes sharing common infrastructure.**

**Shared infrastructure (module-level):**

- Import and reuse `_html_to_markdown` from `bbj_rag.parsers.web_crawl` (do NOT reimplement HTML-to-Markdown conversion)
- Define WordPress-specific chrome selectors list `_WP_CHROME_SELECTORS`:
  ```
  "nav", "script", "style", "noscript", "iframe",
  "header", "footer",
  ".site-header", ".site-footer",
  ".breadcrumb", ".breadcrumbs",
  ".sidebar", ".widget-area",
  ".comments-area", ".post-navigation",
  "#secondary", "#comments",
  ".wp-block-separator",
  ```
- Define `_strip_wp_chrome(soup: BeautifulSoup) -> None` using same pattern as `web_crawl._strip_chrome` but with WordPress selectors. Also strip all `<img>`, `<video>`, `<audio>`, `<iframe>` tags (user decision: text only).
- Define `_fetch_page(client: httpx.Client, url: str, max_retries: int = 1) -> str | None` -- reuse the retry pattern from web_crawl but can be a simplified version or import directly from web_crawl.
- Define `_extract_title_from_soup(soup: BeautifulSoup) -> str` -- extract from `<title>` tag, strip " - BASIS International" and similar suffixes.

**AdvantageParser class:**

`__init__(self, index_url: str = "https://basis.cloud/advantage-index/", rate_limit: float = 1.0, max_retries: int = 1)`

`parse() -> Iterator[Document]`:
1. Call `_discover_article_urls(client, self.index_url)` to get all article URLs
2. If zero URLs found from HTML parsing, try sitemap fallback: fetch `/post-sitemap.xml` and extract `<loc>` URLs matching `/advantage/` pattern
3. For each article URL, fetch the page, strip WordPress chrome, find content using Advantage-specific selectors (try in order): `.entry-content`, `article .post-content`, `article`, `[role='main']`, `main`
4. Convert content HTML to markdown using `_html_to_markdown()`
5. Skip if content is empty after stripping
6. Yield Document:
   - `source_url`: the article URL
   - `title`: extracted from page
   - `doc_type`: `"article"` (Advantage articles are magazine-style articles)
   - `content`: markdown text
   - `generations`: `["bbj"]` (placeholder -- generation tagger classifies downstream via pipeline intelligence)
   - `context_header`: `"Advantage Magazine > {title}"`
   - `metadata`: `{"source": "advantage"}`
   - `deprecated`: False
7. Rate limit between requests (`time.sleep(self.rate_limit)`)

`_discover_article_urls(client, index_url) -> list[str]`:
- Fetch index page, parse with BeautifulSoup
- Find all `<a>` tags with href containing `/advantage/` but NOT the index URL itself
- Deduplicate and return sorted list
- Log count of discovered URLs

**KnowledgeBaseParser class:**

`__init__(self, index_url: str = "https://basis.cloud/knowledge-base/", rate_limit: float = 1.0, max_retries: int = 1)`

`parse() -> Iterator[Document]`:
1. Call `_discover_kb_urls(client, self.index_url)` to get all KB article URLs
2. If zero from HTML, try sitemap fallback at `/kb-sitemap.xml` or `/sitemap.xml`
3. For each KB URL, fetch page, strip WordPress chrome, find content using KB-specific selectors (ECKB plugin, try in order): `#eckb-article-body`, `.eckb-article-content-body`, `article .entry-content`, `article`, `main`
4. Convert to markdown, skip empty
5. Yield Document:
   - `source_url`: the KB URL
   - `title`: extracted from page
   - `doc_type`: `"concept"` (KB articles are knowledge/how-to content)
   - `content`: markdown text
   - `generations`: `["bbj"]` (placeholder for downstream tagger)
   - `context_header`: `"Knowledge Base > {title}"`
   - `metadata`: `{"source": "knowledge_base"}`
   - `deprecated`: False
6. Rate limit between requests

`_discover_kb_urls(client, index_url) -> list[str]`:
- Fetch index page, parse HTML
- Find `<a>` tags with href matching `/knowledge-base/kb` pattern (KB articles follow `/knowledge-base/kb{number}/`)
- Deduplicate and return sorted list

**Important notes:**
- Both parsers pre-populate `generations` with `["bbj"]` as a default. The pipeline integration (Plan 13-04) will handle whether intelligence is re-applied or skipped.
- Use `httpx.Client` context manager with User-Agent header `"bbj-rag-crawler/0.1 (+bbj-ai-strategy)"` (same as web_crawl.py)
- Follow `httpx.Client(timeout=30.0, follow_redirects=True)` pattern from web_crawl.py
- Both parsers should log: URL discovery count, per-article fetch progress, skip reasons
  </action>
  <verify>
Run `uv run python -c "from bbj_rag.parsers.wordpress import AdvantageParser, KnowledgeBaseParser; print('OK')"` to confirm imports.
Run `uv run ruff check src/bbj_rag/parsers/wordpress.py` for lint.
Run `uv run mypy src/bbj_rag/parsers/wordpress.py` for type checking.
  </verify>
  <done>
AdvantageParser and KnowledgeBaseParser classes exist, import cleanly, follow index-then-article crawl pattern, reuse web_crawl._html_to_markdown(), and pass lint + type checks.
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for WordPress parsers</name>
  <files>
    rag-ingestion/tests/test_wordpress_parser.py
  </files>
  <action>
**Create `tests/test_wordpress_parser.py`:**

All tests mock HTTP calls (no real network requests). Use `unittest.mock.patch` on `httpx.Client`.

**AdvantageParser tests:**
1. `test_advantage_parser_implements_protocol` -- isinstance(AdvantageParser(), DocumentParser)
2. `test_advantage_discovers_article_urls` -- Mock index page HTML with `<a href="https://basis.cloud/advantage/some-article/">` links. Verify `_discover_article_urls` returns those URLs.
3. `test_advantage_strips_chrome` -- Mock article page with nav, header, footer, sidebar. Verify those are stripped and only `.entry-content` body remains.
4. `test_advantage_yields_documents` -- Mock index page with 2 article links, mock article pages with content. Verify 2 Documents yielded with correct fields.
5. `test_advantage_sets_doc_type_article` -- Verify doc_type is "article".
6. `test_advantage_context_header` -- Verify context_header is "Advantage Magazine > {title}".
7. `test_advantage_skips_empty_articles` -- Article page with no content yields no Document.
8. `test_advantage_sitemap_fallback` -- Mock index page returning no links. Mock sitemap.xml with article URLs. Verify fallback discovers URLs.

**KnowledgeBaseParser tests:**
9. `test_kb_parser_implements_protocol` -- isinstance check
10. `test_kb_discovers_article_urls` -- Mock index page HTML with `/knowledge-base/kb01069/` style links. Verify discovery.
11. `test_kb_uses_eckb_content_selector` -- Mock KB page with `<div id="eckb-article-body">` containing content. Verify content extracted from ECKB container.
12. `test_kb_yields_documents` -- Mock full flow, verify Documents.
13. `test_kb_sets_doc_type_concept` -- Verify doc_type is "concept".
14. `test_kb_context_header` -- Verify "Knowledge Base > {title}".
15. `test_kb_strips_media` -- Mock page with img, video, audio tags. Verify they are removed.

**Shared tests:**
16. `test_strip_wp_chrome_removes_boilerplate` -- Test `_strip_wp_chrome` directly with sample HTML containing nav/header/footer/sidebar.

Mock strategy: Create realistic HTML snippets for WordPress pages. Use `httpx.MockTransport` or patch `httpx.Client.get` to return canned responses. Each mock response should contain minimal but realistic WordPress HTML structure.
  </action>
  <verify>
Run `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/test_wordpress_parser.py -v` -- all tests pass.
Run `uv run pytest` -- full suite passes (no regressions).
Run `uv run ruff check tests/test_wordpress_parser.py` for lint.
  </verify>
  <done>
16 unit tests all pass. AdvantageParser correctly discovers article URLs, strips WordPress chrome, and yields Documents. KnowledgeBaseParser handles ECKB plugin layout. Both parsers strip media, set correct doc_type and context_header. No regressions in existing test suite.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_wordpress_parser.py -v` -- all 16 tests pass
2. `uv run pytest` -- full suite passes
3. `uv run ruff check src/bbj_rag/parsers/wordpress.py tests/test_wordpress_parser.py` -- clean
4. `uv run mypy src/bbj_rag/parsers/wordpress.py` -- type checks pass
5. `isinstance(AdvantageParser(), DocumentParser)` -- True
6. `isinstance(KnowledgeBaseParser(), DocumentParser)` -- True
</verification>

<success_criteria>
- AdvantageParser discovers article URLs from index page (with sitemap.xml fallback)
- KnowledgeBaseParser discovers KB URLs from index page
- Both strip WordPress boilerplate and media (images, video, audio)
- Advantage uses `.entry-content` content selector; KB uses `#eckb-article-body` ECKB selector
- Both reuse `_html_to_markdown` from web_crawl module (not reimplemented)
- 16 unit tests pass with mocked HTTP (no network required)
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/13-additional-parsers/13-02-SUMMARY.md`
</output>
