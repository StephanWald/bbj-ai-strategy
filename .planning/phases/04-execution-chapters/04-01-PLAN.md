---
phase: 04-execution-chapters
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/04-ide-integration/index.md
autonomous: true

must_haves:
  truths:
    - "A developer reader understands the two-layer completion architecture: deterministic (Langium) and generative (LLM)"
    - "A reader understands why Copilot BYOK does not solve the inline completion problem for BBj"
    - "The chapter presents the shipped bbj-language-server as the foundation for AI integration"
    - "The chapter explains generation-aware completion with concrete examples"
    - "A Current Status section honestly states what is shipped, in progress, and planned"
  artifacts:
    - path: "docs/04-ide-integration/index.md"
      provides: "Chapter 4: IDE Integration"
      min_lines: 300
      contains: "TL;DR"
  key_links:
    - from: "docs/04-ide-integration/index.md"
      to: "/docs/fine-tuning"
      via: "cross-reference link"
      pattern: "/docs/fine-tuning"
    - from: "docs/04-ide-integration/index.md"
      to: "/docs/rag-database"
      via: "cross-reference link"
      pattern: "/docs/rag-database"
---

<objective>
Write Chapter 4: IDE Integration -- covering the VSCode extension architecture, Langium-based language server, two completion mechanisms (popup and ghost text), generation-aware prompting, and both the custom LLM client path and Copilot bridge path.

Purpose: Chapter 4 is the first execution chapter. It connects the fine-tuned model from Chapter 3 to the developer's daily workflow through IDE integration. A developer reader should understand exactly how AI-powered BBj completion works architecturally.

Output: Complete Chapter 4 replacing the current placeholder (~14 lines) with a researched, execution-depth chapter (~300-400 lines) matching Chapter 3's depth and following all established content patterns.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-execution-chapters/04-CONTEXT.md
@.planning/phases/04-execution-chapters/04-RESEARCH.md

# Source material from the strategy paper (lines 311-499)
@bbj-llm-strategy.md

# Pattern reference -- Chapter 3 is the depth target
@docs/03-fine-tuning/index.md

# Pattern reference -- Chapter 1 for overall tone
@docs/01-bbj-challenge/index.mdx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write Chapter 4 -- IDE Integration</name>
  <files>docs/04-ide-integration/index.md</files>
  <action>
Read the source material and research, then replace the placeholder content in docs/04-ide-integration/index.md with a complete chapter. The chapter MUST follow these structural and content requirements:

**Source material to absorb before writing:**
1. bbj-llm-strategy.md lines 311-499 (Component 2: VSCode Extension with Langium Integration)
2. .planning/phases/04-execution-chapters/04-RESEARCH.md -- Chapter 4 sections (IDE Integration Landscape, bbj-language-server repo details, Langium framework, VSCode Inline Completion API, LSP 3.18, Copilot BYOK, Continue.dev)
3. .planning/phases/04-execution-chapters/04-CONTEXT.md -- Chapter 4 framing decisions

**Required structure (follow this order):**

1. **Frontmatter** -- keep existing sidebar_position: 1, update title and description if needed
2. **TL;DR block** (:::tip[TL;DR]) -- 2-3 sentences covering: existing language server as foundation, two completion paths (deterministic + generative), and the Copilot bridge as interim step
3. **Opening paragraph** -- Vision-forward framing: lead with the AI-powered IDE vision, then reference the shipped language server as the foundation it builds on. Connect back to Chapter 3 (the model is built, now how does it reach the developer?)
4. **The Foundation: bbj-language-server** -- Document the REAL shipped product (v0.5.0, Langium-based, 450+ commits, 13 contributors, MIT, on VS Code Marketplace). Features: syntax highlighting, code completion, diagnostics, formatting, BBj Properties viewing, code execution. This is NOT a future plan -- it is shipped.
5. **Two Completion Mechanisms** -- Explain popup completion (Langium, deterministic, <10ms) vs ghost text (LLM, generative, 200-1000ms). Use a comparison table. Include a Decision callout (:::info[Decision: ...]) explaining why both are needed.
6. **Ghost Text Architecture** -- How InlineCompletionItemProvider works. Include the TypeScript code example from RESEARCH.md. Explain the lifecycle: user types -> debounce -> extract context from Langium -> assemble prompt -> call Ollama -> render ghost text.
7. **Generation-Aware Completion** -- How the Langium parser detects code generation (DWC signals, BBj GUI signals, Visual PRO/5 signals, character signals). Include the GenerationContext interface and detectGeneration function from the strategy paper. Include the enriched prompt example showing how generation context shapes the LLM request.
8. **LSP 3.18: Server-Side Inline Completion** -- Explain textDocument/inlineCompletion as protocol-level feature. This means completion can live in the language server itself (architecturally cleaner for Langium). Include the server-side handler code example from RESEARCH.md. Mention editor adoption (Neovim merged, Helix PR, etc.).
9. **The Copilot Bridge** -- BYOK with Ollama: what works (chat) and what does NOT work (inline completions). Be clear about the limitation. Present this as an interim bridge, not the strategic path. Reference the extension being deprecated and merged into Copilot Chat. Include the VS Code settings JSON from RESEARCH.md. Decision callout: Copilot bridge is complementary, not primary.
10. **Mermaid diagram** -- IDE Extension Architecture diagram from RESEARCH.md (graph TD with VSCode Extension, Language Server, AI Backend subgraphs). Place after the ghost text architecture section.
11. **Langium AI** -- Brief mention of langium-ai-tools as emerging bridge between Langium parsers and LLM integration. Note version compatibility uncertainty (targets 3.4.x while bbj-language-server is on Langium 4.x). Frame as "an initiative to watch" not a dependency.
12. **Current Status** -- Use :::note[Where Things Stand -- January 2026] admonition. Shipped: language server v0.5.0. In progress: fine-tuned model (~10K data points, promising results), Copilot integration in early exploration. Planned: LLM ghost text, generation detection, semantic context API.
13. **Cross-references** -- Link to /docs/fine-tuning (model), /docs/rag-database (context source), /docs/implementation-roadmap (timeline). Link to /docs/strategic-architecture for the unified infrastructure concept.

**Content patterns to follow (match Chapter 3 style):**
- :::tip[TL;DR] at top
- At least 2 :::info[Decision: ...] callouts
- At least 1 Mermaid diagram (the architecture diagram)
- TypeScript code examples with syntax highlighting
- Architecture-first framing: describe requirements/design, reference tools as current examples
- Inline citations with links where referencing external sources
- No "Coming Soon" text anywhere

**What to AVOID:**
- Do NOT copy the strategy paper verbatim -- rewrite with current research findings
- Do NOT claim Copilot BYOK supports inline completions (it does NOT, only chat)
- Do NOT present the Copilot extension as current -- it is being deprecated and merged into Chat
- Do NOT hard-code tool recommendations without "as of [date]" framing
- Do NOT make the chapter shorter than 300 lines -- match Chapter 3's depth (~400 lines)
- Do NOT use .mdx extension -- this chapter uses only Markdown features (no Tabs/JSX needed)
  </action>
  <verify>
Run `npm run build` from the project root. Build must pass with zero errors. Then verify:
1. File exists and is >300 lines: `wc -l docs/04-ide-integration/index.md`
2. Contains TL;DR: `grep -c "TL;DR" docs/04-ide-integration/index.md`
3. Contains Decision callouts: `grep -c ":::info\[Decision:" docs/04-ide-integration/index.md`
4. Contains Mermaid diagram: `grep -c "mermaid" docs/04-ide-integration/index.md`
5. Contains Current Status: `grep -c "Current Status" docs/04-ide-integration/index.md`
6. No "Coming Soon": `grep -c "Coming Soon" docs/04-ide-integration/index.md` returns 0
7. Cross-references exist: `grep -c "/docs/" docs/04-ide-integration/index.md`
  </verify>
  <done>
Chapter 4 is a complete, build-passing chapter of 300+ lines covering the VSCode extension architecture, Langium foundation, two completion mechanisms, generation-aware prompting, Copilot bridge limitations, and an honest Current Status section. A developer reader can understand how AI-powered BBj completion works end-to-end.
  </done>
</task>

</tasks>

<verification>
- `npm run build` passes with zero errors
- Chapter 4 replaces placeholder with substantive content (300+ lines)
- All content patterns present: TL;DR, Decision callouts, Mermaid diagram, Current Status
- Cross-references to at least 3 other chapters
- No factual errors about Copilot BYOK (chat only, not inline completions)
- bbj-language-server described accurately as shipped product (v0.5.0, MIT, Marketplace)
</verification>

<success_criteria>
A developer reading Chapter 4 understands: (1) the shipped bbj-language-server as the foundation, (2) how popup and ghost text completion differ, (3) how generation detection shapes LLM prompts, (4) why Copilot BYOK is limited to chat, and (5) the path forward for AI-powered IDE integration. The chapter builds with zero errors and matches Chapter 3's depth.
</success_criteria>

<output>
After completion, create `.planning/phases/04-execution-chapters/04-01-SUMMARY.md`
</output>
