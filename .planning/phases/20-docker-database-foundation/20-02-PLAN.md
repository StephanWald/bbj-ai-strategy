---
phase: 20-docker-database-foundation
plan: 02
type: execute
wave: 2
depends_on: ["20-01"]
files_modified:
  - rag-ingestion/src/bbj_rag/config.py
  - rag-ingestion/src/bbj_rag/db.py
  - rag-ingestion/src/bbj_rag/startup.py
  - rag-ingestion/src/bbj_rag/app.py
  - rag-ingestion/src/bbj_rag/health.py
autonomous: false

must_haves:
  truths:
    - "Settings loads from environment variables alone when config.toml is absent"
    - "Settings still loads from config.toml when the file is present (backward compat)"
    - "App refuses to start with clear error when required env vars are missing"
    - "Startup summary logs Python version, DB host, Ollama URL, embedding model, and environment"
    - "Schema is applied idempotently on every app startup"
    - "`docker compose up` starts both containers to healthy state"
    - "Health endpoint reports DB and Ollama connectivity status"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/config.py"
      provides: "Settings with conditional TOML source and separate DB credential fields"
      contains: "db_host"
    - path: "rag-ingestion/src/bbj_rag/db.py"
      provides: "get_connection accepting Settings or keyword args"
      contains: "get_connection"
    - path: "rag-ingestion/src/bbj_rag/startup.py"
      provides: "Environment validation and startup summary logging"
      contains: "log_startup_summary"
    - path: "rag-ingestion/src/bbj_rag/app.py"
      provides: "FastAPI app with lifespan handler that applies schema and logs startup"
      contains: "lifespan"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/config.py"
      to: "config.toml"
      via: "conditional Path.exists() check"
      pattern: "Path.*exists"
    - from: "rag-ingestion/src/bbj_rag/app.py"
      to: "rag-ingestion/src/bbj_rag/startup.py"
      via: "lifespan calls log_startup_summary"
      pattern: "log_startup_summary"
    - from: "rag-ingestion/src/bbj_rag/app.py"
      to: "rag-ingestion/src/bbj_rag/schema.py"
      via: "lifespan calls apply_schema"
      pattern: "apply_schema"
    - from: "rag-ingestion/src/bbj_rag/health.py"
      to: "rag-ingestion/src/bbj_rag/config.py"
      via: "health endpoint reads Settings for DB connection"
      pattern: "Settings|database_url|db_host"
---

<objective>
Refactor the configuration system to work from environment variables alone (Docker) while maintaining TOML backward compatibility (local dev), create the startup validation and summary logger, wire schema application into the app lifespan, and verify the full Docker stack starts to healthy state.

Purpose: Complete the Docker foundation -- after this plan, `docker compose up` produces two healthy containers with schema applied, Ollama reachable, and source data mounted.
Output: Refactored config.py, updated db.py, new startup.py, wired app.py with lifespan, verified Docker stack
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-docker-database-foundation/20-CONTEXT.md
@.planning/phases/20-docker-database-foundation/20-RESEARCH.md
@.planning/phases/20-docker-database-foundation/20-01-SUMMARY.md

# Existing source files (will be modified)
@rag-ingestion/src/bbj_rag/config.py
@rag-ingestion/src/bbj_rag/db.py
@rag-ingestion/src/bbj_rag/schema.py
@rag-ingestion/src/bbj_rag/embedder.py
@rag-ingestion/src/bbj_rag/app.py
@rag-ingestion/src/bbj_rag/health.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor config.py + update db.py + create startup.py</name>
  <files>
    rag-ingestion/src/bbj_rag/config.py
    rag-ingestion/src/bbj_rag/db.py
    rag-ingestion/src/bbj_rag/startup.py
  </files>
  <action>
**config.py** -- Refactor the Settings class with these changes:

1. **Conditional TOML source** (CRITICAL -- fixes the Docker crash):
   Replace the unconditional `TomlConfigSettingsSource(settings_cls)` in `settings_customise_sources` with a conditional check: only include TOML source when `Path("config.toml").exists()`. Import `Path` from `pathlib`. This is the exact pattern from the research document.

2. **Separate DB credential fields** (per user decision):
   Replace the single `database_url` field with five separate fields:
   - `db_host: str = Field(default="localhost")`
   - `db_port: int = Field(default=5432)`
   - `db_user: str = Field(default="postgres")`
   - `db_password: str = Field(default="postgres")`
   - `db_name: str = Field(default="bbj_rag")`

3. **Add database_url as a computed property** (not a Field):
   ```python
   @property
   def database_url(self) -> str:
       return f"postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/{self.db_name}"
   ```
   This maintains backward compatibility -- any code that reads `settings.database_url` still works.

4. **Keep all other fields unchanged** (embedding_model, embedding_dimensions, chunk_size, etc.).

5. **Remove the `_toml_source` ClassVar** since TOML is now conditionally included.

**IMPORTANT backward compatibility:** The existing `config.toml` file has `database_url = "postgresql://..."` as a single field. With the refactor, TOML users will need to update their config.toml to use the separate fields (or rely on the defaults). Since `database_url` is no longer a Field on Settings, the TOML `database_url` key will be silently ignored. This is acceptable -- the TOML file is for local dev and has defaults that work (`localhost:5432`). Document this change in a comment.

**db.py** -- Update `get_connection` to support both calling patterns:

The function currently accepts `database_url: str`. Change it to also accept keyword args from Settings. The cleanest approach: add an overload that accepts a Settings object, OR change the signature to accept keyword args:

```python
def get_connection(
    database_url: str | None = None,
    *,
    host: str = "localhost",
    port: int = 5432,
    user: str = "postgres",
    password: str = "postgres",
    dbname: str = "bbj_rag",
) -> psycopg.Connection[tuple[object, ...]]:
```

When `database_url` is provided, use it directly (backward compat). When `None`, build the connection from keyword args using `psycopg.connect(host=host, port=port, user=user, password=password, dbname=dbname)`.

Add a convenience function `get_connection_from_settings(settings: Settings)` that extracts the fields and calls `get_connection`. This keeps the API clean.

Also update any callers within the module if needed (there are none currently -- callers are in pipeline.py and cli.py which pass `settings.database_url`).

**startup.py** -- New module with two functions:

1. `validate_environment()` -- Checks that critical env vars are set. In Docker (when `ENV != "development"` and no `config.toml` present), `BBJ_RAG_DB_PASSWORD` should not be the default "postgres" value. This is a soft warning, not a hard fail, since the defaults are technically functional. The hard fail is if Settings cannot be instantiated (pydantic handles that).

2. `log_startup_summary(settings: Settings)` -- Logs a structured startup summary using Python's `logging` module at INFO level. Include:
   - Python version (`sys.version`)
   - DB Host: `{settings.db_host}:{settings.db_port}`
   - DB Name: `{settings.db_name}`
   - DB User: `{settings.db_user}`
   - Ollama: `{os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")}`
   - Embedding: `{settings.embedding_model}` ({settings.embedding_dimensions}d)
   - Environment: `{os.environ.get("ENV", "production")}`
   - Data mount: check if `/data` directory exists and list subdirectories if present

   Format as a clear bordered block (use `=` separators). Never log the password.

After creating these files, run the existing test suite to confirm backward compatibility. The config.py refactor must not break existing tests that construct Settings objects.
  </action>
  <verify>
Run from `rag-ingestion/` directory:
- `uv run pytest tests/ -x -q` -- all existing tests pass (config refactor is backward compatible)
- `uv run python -c "from bbj_rag.config import Settings; s = Settings(); print(s.database_url)"` -- prints valid postgresql:// URL from defaults
- `uv run python -c "from bbj_rag.config import Settings; s = Settings(); print(s.db_host, s.db_port, s.db_name)"` -- prints separate DB fields
- `BBJ_RAG_DB_HOST=myhost BBJ_RAG_DB_PORT=9999 uv run python -c "from bbj_rag.config import Settings; s = Settings(); print(s.database_url)"` -- prints URL with myhost:9999
- `uv run python -c "from bbj_rag.startup import log_startup_summary, validate_environment"` -- imports without error
- `uv run python -c "from bbj_rag.db import get_connection_from_settings"` -- imports without error
  </verify>
  <done>
config.py works from env vars alone (no TOML crash), has separate DB fields with database_url property, and maintains backward compatibility. db.py supports keyword arg connections. startup.py provides environment validation and structured startup summary logging. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire app.py lifespan + update health.py + Docker integration test</name>
  <files>
    rag-ingestion/src/bbj_rag/app.py
    rag-ingestion/src/bbj_rag/health.py
  </files>
  <action>
**app.py** -- Add a FastAPI lifespan context manager that runs on startup:

```python
from contextlib import asynccontextmanager
from fastapi import FastAPI
from bbj_rag.health import router as health_router

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    from bbj_rag.config import Settings
    from bbj_rag.startup import log_startup_summary, validate_environment
    from bbj_rag.schema import apply_schema
    from bbj_rag.db import get_connection_from_settings
    import logging

    logging.basicConfig(level=logging.INFO, format="%(message)s")

    validate_environment()
    settings = Settings()
    log_startup_summary(settings)

    # Apply schema idempotently
    conn = get_connection_from_settings(settings)
    try:
        apply_schema(conn)
        logging.getLogger("bbj_rag.startup").info("Schema applied successfully")
    finally:
        conn.close()

    yield
    # Shutdown (nothing to clean up yet)

app = FastAPI(title="BBJ RAG", lifespan=lifespan)
app.include_router(health_router)
```

The imports are inside the lifespan function to avoid circular imports and to keep the module importable without side effects (important for testing).

**health.py** -- Update to use the refactored Settings with separate DB fields:

The health endpoint should now connect using keyword args from Settings (not the old `database_url` string). Use `psycopg.connect(host=..., port=..., user=..., password=..., dbname=...)` directly in the health check, or call `get_connection_from_settings`. Using a direct connection is simpler for a health check since we just need `SELECT 1`.

Make sure the health endpoint returns HTTP 503 (not 200) when any check fails. Use `from fastapi.responses import JSONResponse` and return `JSONResponse(content=result, status_code=503)` when degraded.

**Docker integration test** (manual verification, executed by this task):

1. Copy `.env.example` to `.env` in `rag-ingestion/`
2. Set `POSTGRES_USER=bbj`, `POSTGRES_PASSWORD=changeme`, `POSTGRES_DB=bbj_rag` in `.env` (matching the BBJ_RAG_ vars)
3. Run `docker compose up --build -d` from `rag-ingestion/`
4. Wait for both containers to become healthy: `docker compose ps` should show both services as "healthy"
5. Test health endpoint: `curl -s http://localhost:10800/health | python -m json.tool`
   - DB should be "ok" (schema applied, connection works)
   - Ollama may be "ok" or "error" depending on whether Ollama is running on host
6. Verify schema was applied: `docker compose exec db psql -U bbj -d bbj_rag -c "\dt"` should show the `chunks` table
7. Verify source data mount: `docker compose exec app ls /data/` should list directory contents (or be empty if no data exists at the mount path)
8. Check startup logs: `docker compose logs app` should show the startup summary with all configuration values
9. Clean up: `docker compose down`

If Ollama is not running on the host, the health endpoint should return `{"status": "degraded", "checks": {"database": "ok", "ollama": "error: ..."}}` with HTTP 503. This is expected and correct -- Ollama connectivity is verified but not required for the containers to start.
  </action>
  <verify>
Run from `rag-ingestion/` directory:
- `uv run pytest tests/ -x -q` -- all tests pass
- `cp .env.example .env` (if not already done)
- `docker compose up --build -d` -- both containers start
- `docker compose ps` -- both services show "healthy" (app may show "healthy" even with Ollama error -- health check uses curl -f which fails on 503, so app will show "unhealthy" if Ollama is not running. This is expected behavior per Docker HEALTHCHECK semantics. The key test is that the DB health check passes.)
- `curl -s http://localhost:10800/health` -- returns JSON with database: "ok"
- `docker compose exec db psql -U bbj -d bbj_rag -c "\dt"` -- shows chunks table
- `docker compose logs app | grep "Startup Summary"` -- shows startup summary
- `docker compose down` -- clean shutdown
  </verify>
  <done>
app.py has lifespan that validates environment, loads settings, logs startup summary, and applies schema. health.py uses refactored Settings with separate DB fields. Docker stack starts successfully: both containers reach healthy state, schema is applied, health endpoint responds, and startup summary is logged.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Docker + Database foundation: docker compose up starts pgvector and Python app containers with schema applied, health endpoint serving, and startup summary logged.</what-built>
  <how-to-verify>
From the `rag-ingestion/` directory:

1. Run `docker compose up -d` (should already be running from Task 2)
2. Check both containers are running: `docker compose ps`
3. Hit the health endpoint: `curl -s http://localhost:10800/health | python -m json.tool`
   - Verify `database` shows `ok`
   - Verify `ollama` shows status (ok if running, error message if not -- both are acceptable)
4. Verify schema exists: `docker compose exec db psql -U bbj -d bbj_rag -c "\dt"`
   - Should show `chunks` table
5. Check startup logs: `docker compose logs app | head -30`
   - Should show startup summary with DB host, Ollama URL, embedding model
6. Test reset script: `bash scripts/reset-db.sh`
   - Should wipe database and restart cleanly
7. Verify source data mount: `docker compose exec app ls /data/`
   - Should show directory listing (contents depend on INGESTION_DATA_PATH)
8. Clean up: `docker compose down`
  </how-to-verify>
  <resume-signal>Type "approved" or describe any issues you see</resume-signal>
</task>

</tasks>

<verification>
Phase 20 success criteria check:
1. `docker compose up` starts both containers and they reach healthy state -- verified by `docker compose ps`
2. pgvector schema exists after startup -- verified by `\dt` in psql showing `chunks` table
3. App container can reach host Ollama -- verified by health endpoint reporting Ollama status
4. App container can read mounted source data -- verified by `ls /data/` inside container
5. Settings load from environment variables without TOML -- verified by container starting without config.toml
</verification>

<success_criteria>
- `docker compose up` brings both containers to healthy state
- Health endpoint at :10800/health reports DB connectivity
- pgvector schema (chunks table + indexes) applied after first startup
- Settings work purely from env vars (no config.toml in container)
- Startup summary logged with configuration values
- Reset script wipes and reinitializes successfully
- All 310 existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/20-docker-database-foundation/20-02-SUMMARY.md`
</output>
