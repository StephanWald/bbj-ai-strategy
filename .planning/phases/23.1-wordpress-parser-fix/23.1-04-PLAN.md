---
phase: 23.1-wordpress-parser-fix
plan: 04
type: execute
wave: 1
depends_on: []
files_modified: []
autonomous: false
gap_closure: true

must_haves:
  truths:
    - "WordPress Advantage chunks exist in the database with source_url containing 'basis.cloud/advantage'"
    - "Database contains article doc_type chunks from Advantage source (non-zero count)"
    - "PDF documents from Advantage index are present in database as clean markdown text, not binary garbage"
    - "/stats endpoint shows article doc_type in by_source breakdown"
    - "Search query for 'BASIS partner success story' returns Advantage magazine content"
  artifacts:
    - path: "database"
      provides: "Advantage article chunks (expected ~1,800 chunks from ~281 articles)"
    - path: "database"
      provides: "PDF document chunks from Advantage index with format=pdf metadata"
  key_links:
    - from: "wordpress.py AdvantageParser"
      to: "database chunks table"
      via: "pipeline.run_pipeline() -> bulk_insert_chunks()"
      pattern: "source_url LIKE '%basis.cloud/advantage%'"
    - from: "/stats endpoint"
      to: "database"
      via: "SELECT doc_type, count(*) GROUP BY doc_type"
      pattern: "article.*[0-9]+"
---

<objective>
Re-ingest the WordPress Advantage source and verify chunks land in the database.

Purpose: Phase 23.1 verification found that the database has ZERO Advantage chunks despite the 23.1-03 SUMMARY claiming 281 articles producing 1,801 chunks. The parser code is correct (tests pass), configuration is correct (sources.toml has wordpress-advantage enabled), but the data is not in the database. This gap closure plan re-runs Advantage ingestion with diagnostic logging, then verifies the chunks actually exist in the database.

Output: Database populated with Advantage article chunks (including PDF-extracted content), verified via /stats and /search endpoints.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23.1-wordpress-parser-fix/23.1-VERIFICATION.md
@.planning/phases/23.1-wordpress-parser-fix/23.1-03-SUMMARY.md
@rag-ingestion/sources.toml
@rag-ingestion/src/bbj_rag/ingest_all.py
@rag-ingestion/src/bbj_rag/parsers/wordpress.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Diagnose and re-ingest WordPress Advantage source</name>
  <files>(no code changes — operational task)</files>
  <action>
Investigate why Advantage chunks are missing, then re-ingest:

1. **Check current database state** — Confirm the gap by querying the running database:
   ```bash
   docker compose exec db psql -U bbj -d bbj_rag -c \
     "SELECT count(*) FROM chunks WHERE source_url LIKE '%basis.cloud/advantage%';"
   ```
   Expected: 0 rows (confirming the gap).

2. **Check /stats endpoint** — Verify current doc_type distribution:
   ```bash
   curl -s http://localhost:10800/stats | python3 -m json.tool
   ```
   Note the current total and confirm no 'article' doc_type for Advantage.

3. **If Docker services are not running**, start them:
   ```bash
   cd rag-ingestion && docker compose up -d
   ```
   Wait for health check: `curl -s http://localhost:10800/health`

4. **Re-ingest ONLY the wordpress-advantage source** with verbose logging and clean flag to avoid duplicates:
   ```bash
   docker compose exec app bbj-ingest-all \
     --source wordpress-advantage \
     --clean \
     --verbose
   ```
   This runs only the Advantage parser (not all 9 sources), cleaning any stale data first.
   Watch for: number of articles discovered, chunks created, any errors/exceptions.
   Expected runtime: ~10 minutes (based on prior run showing 639.8s for 281 articles).

5. **If ingestion fails**, capture the full error output. Common issues:
   - Network timeout fetching basis.cloud (retry or check connectivity)
   - PDF extraction failure (check pymupdf import inside container)
   - Database write failure (check connection, disk space)

6. **After ingestion completes**, verify chunks landed:
   ```bash
   docker compose exec db psql -U bbj -d bbj_rag -c \
     "SELECT count(*) FROM chunks WHERE source_url LIKE '%basis.cloud/advantage%';"
   ```
   Expected: ~1,800 chunks (281 articles * ~6.4 chunks/article average).

7. **Check for PDF-specific chunks**:
   ```bash
   docker compose exec db psql -U bbj -d bbj_rag -c \
     "SELECT source_url, title, length(content) FROM chunks WHERE source_url LIKE '%.pdf%' LIMIT 10;"
   ```
   Expected: rows with .pdf URLs showing readable content (not binary garbage).

8. **Verify /stats now includes article doc_type**:
   ```bash
   curl -s http://localhost:10800/stats | python3 -m json.tool
   ```
   Expected: by_source includes "article" or "concept" entries for Advantage content, total_chunks increased by ~1,800.
  </action>
  <verify>
- `SELECT count(*) FROM chunks WHERE source_url LIKE '%basis.cloud/advantage%'` returns > 0
- /stats endpoint total_chunks has increased by ~1,800 compared to pre-ingestion value
- No error output from bbj-ingest-all command
  </verify>
  <done>Advantage article chunks exist in the database with non-zero count, PDF chunks are present with clean text content, /stats reflects the new data.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Re-ingested WordPress Advantage source into pgvector database. Advantage article chunks and PDF content should now be present and searchable.</what-built>
  <how-to-verify>
1. Check search quality — run a query that should hit Advantage content:
   ```bash
   curl -s http://localhost:10800/search \
     -H "Content-Type: application/json" \
     -d '{"query": "BASIS partner success story", "limit": 5}' | python3 -m json.tool
   ```
   Verify: Results include Advantage magazine articles with readable content, source_url contains basis.cloud/advantage.

2. Check PDF content quality — search for a known PDF topic:
   ```bash
   curl -s http://localhost:10800/search \
     -H "Content-Type: application/json" \
     -d '{"query": "BBj Advantage magazine", "limit": 5}' | python3 -m json.tool
   ```
   Verify: Results include content extracted from PDF documents (not binary garbage).

3. Verify /stats shows complete corpus:
   ```bash
   curl -s http://localhost:10800/stats | python3 -m json.tool
   ```
   Verify: total_chunks is ~50,000+ (48,594 prior + ~1,800 new Advantage chunks).
  </how-to-verify>
  <resume-signal>Type "approved" if search results look good, or describe issues found.</resume-signal>
</task>

</tasks>

<verification>
After both tasks complete:
1. Database query `SELECT count(*) FROM chunks WHERE source_url LIKE '%basis.cloud/advantage%'` returns > 1000
2. `/stats` endpoint shows total_chunks > 49,000
3. Search for "BASIS partner" returns Advantage magazine content
4. No binary garbage in any search results
5. PDF-sourced chunks have readable markdown text content
</verification>

<success_criteria>
- WordPress Advantage chunks are present in the database (closes the primary gap from VERIFICATION.md)
- PDF documents from Advantage index are extractable and searchable
- /stats endpoint reflects the complete corpus including Advantage content
- Search quality is maintained (no corrupted or binary content)
</success_criteria>

<output>
After completion, create `.planning/phases/23.1-wordpress-parser-fix/23.1-04-SUMMARY.md`
</output>
