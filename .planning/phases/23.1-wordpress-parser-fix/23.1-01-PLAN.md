---
phase: 23.1-wordpress-parser-fix
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rag-ingestion/src/bbj_rag/parsers/wordpress.py
  - rag-ingestion/tests/test_wordpress_parser.py
autonomous: true

must_haves:
  truths:
    - "PDF URLs on the Advantage index page are detected and extracted as markdown text, not parsed as HTML"
    - "URLs that redirect to PDFs (no .pdf extension in original URL) are detected via Content-Type header and handled as PDFs"
    - "Relative hrefs on the index page are resolved to absolute URLs"
    - "All existing WordPress parser tests pass alongside new Content-Type tests"
    - "Batch embedding path is verified: pipeline.py batches chunks (batch_size=64) and calls embedder.embed_batch() which passes a list to ollama.embed(input=texts)"
  artifacts:
    - path: "rag-ingestion/src/bbj_rag/parsers/wordpress.py"
      provides: "WordPress parser with PDF handling and Content-Type fallback detection"
      contains: "application/pdf"
    - path: "rag-ingestion/tests/test_wordpress_parser.py"
      provides: "Tests for Content-Type-based PDF detection and mixed URL handling"
      contains: "content-type"
  key_links:
    - from: "rag-ingestion/src/bbj_rag/parsers/wordpress.py"
      to: "httpx.Response.headers"
      via: "Content-Type header check in parse loop"
      pattern: "application/pdf.*content.type"
---

<objective>
Fix the WordPress parser to correctly handle PDFs linked from the Advantage index page, and add Content-Type-based format detection for redirected URLs that do not have `.pdf` in the path.

Purpose: PDFs were being fetched and parsed as HTML by BeautifulSoup, producing binary garbage chunks in the database. This plan commits the working tree fix (PDF handling + relative URL resolution + import cleanup) and adds the missing Content-Type fallback detection for URLs that redirect to PDF responses.

Output: A working WordPress parser that handles both extension-based and Content-Type-based PDF detection, with comprehensive tests. Batch embedding verified as already functional in the ingestion pipeline.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@rag-ingestion/src/bbj_rag/parsers/wordpress.py
@rag-ingestion/tests/test_wordpress_parser.py
@rag-ingestion/src/bbj_rag/embedder.py
@rag-ingestion/src/bbj_rag/pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Content-Type-based PDF detection to AdvantageParser.parse()</name>
  <files>rag-ingestion/src/bbj_rag/parsers/wordpress.py</files>
  <action>
The working tree already has the partial fix committed: `_is_pdf_url()`, `_fetch_pdf_bytes()`, `_parse_pdf_bytes()`, `_title_from_pdf_url()`, `urljoin` import, and relative URL resolution. These changes are unstaged.

First, stage and commit the existing working tree changes as-is (they are correct and tested).

Then add Content-Type fallback detection. In the `AdvantageParser.parse()` method, after the `else` branch that fetches HTML via `_fetch_page()`, add a Content-Type check: when the URL is NOT a PDF by extension but the response Content-Type contains `application/pdf`, treat the response as PDF bytes instead of HTML.

Implementation approach (from RESEARCH.md "Option B"):
1. Add a new `_fetch_response()` helper function that returns the raw `httpx.Response` object (or None on failure), with the same retry logic as `_fetch_page()`.
2. In the `else` branch of `AdvantageParser.parse()` (the non-PDF-URL branch), replace the `_fetch_page()` call with `_fetch_response()`.
3. Check `resp.headers.get("content-type", "")` -- if it contains `"application/pdf"` (case-insensitive via `.lower()`), call `self._parse_pdf_bytes(url, resp.content)` and yield the document.
4. Otherwise, proceed with HTML parsing using `resp.text` as before.

Content-Type headers can include parameters like `application/pdf; charset=utf-8`, so use substring check: `"application/pdf" in content_type.lower()`.

Keep `_fetch_page()` as-is for backward compatibility (KnowledgeBaseParser still uses it).
  </action>
  <verify>
Run: `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/test_wordpress_parser.py -v`
All existing tests pass. The new `_fetch_response()` helper is importable and returns `httpx.Response | None`.
  </verify>
  <done>
`_fetch_response()` helper exists. `AdvantageParser.parse()` checks Content-Type header on non-PDF-URL responses and routes to PDF handling when `application/pdf` is detected. All existing tests still pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for Content-Type-based PDF detection</name>
  <files>rag-ingestion/tests/test_wordpress_parser.py</files>
  <action>
Add tests to `test_wordpress_parser.py` covering the Content-Type fallback:

1. **`TestContentTypePdfDetection` class** with these tests:

   a. `test_redirect_url_detected_as_pdf_via_content_type` -- An index page links to a URL like `https://basis.cloud/advantage/some-redirect/` (no `.pdf` extension). The mock response for that URL returns `status_code=200` with `content-type: application/pdf` header and bytes content. The parser should yield a Document with `metadata["format"] == "pdf"`.

   b. `test_content_type_with_params_detected` -- Same as above but Content-Type is `application/pdf; charset=utf-8`. Should still detect as PDF.

   c. `test_html_content_type_parsed_normally` -- URL without `.pdf` extension returns `content-type: text/html`. Should be parsed as normal HTML article.

Update `_mock_get()` to support setting Content-Type headers on mock responses. Add a `content_type` field to the url_map dict values -- when present, set `resp.headers` to `{"content-type": content_type}`. When absent, default to `text/html` for str values and `application/pdf` for bytes values.

Also add an import for `_fetch_response` from `bbj_rag.parsers.wordpress` if the function is public (it should be module-level).

2. Run full test suite with `make check` to ensure lint, typecheck, and all tests pass.
  </action>
  <verify>
Run: `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/test_wordpress_parser.py -v`
All tests pass including the 3 new Content-Type tests.
Run: `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && make check`
Lint, typecheck, and full test suite pass.
  </verify>
  <done>
3 new Content-Type detection tests pass. `make check` passes (ruff lint, mypy typecheck, all tests).
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify batch embedding is already functional in the ingestion pipeline</name>
  <files>rag-ingestion/src/bbj_rag/embedder.py, rag-ingestion/src/bbj_rag/pipeline.py</files>
  <action>
The user's phase context requires batch embedding optimization. Research (23.1-RESEARCH.md) found that batch embedding is ALREADY implemented in the codebase. This task verifies that finding by inspecting the code path and documenting it.

Verify the following code flow exists and is correct:

1. **pipeline.py** -- Confirm `IngestPipeline.run()` (or equivalent entry point) accumulates chunks and calls `embed_batch()` with a configurable `batch_size` (expected: 64). Look for the batch accumulation loop and the `embed_batch()` call.

2. **embedder.py** -- Confirm `OllamaEmbedder.embed_batch(texts: list[str])` passes the full list to `ollama.embed(model=..., input=texts)` in a single API call (not looping over individual texts). This is the key optimization -- one HTTP request per batch, not one per chunk.

3. **Confirm there is NO single-embed fallback path** that silently downgrades to 1-at-a-time calls during normal ingestion. The only `embed()` (single) method should be for individual queries at search time, not used during ingestion.

If all three checks pass, no code changes are needed. Add a brief comment at the top of the SUMMARY noting: "Batch embedding verified: pipeline.py batches chunks (batch_size=64) → embedder.embed_batch() → ollama.embed(input=texts). No code changes required -- batching was already implemented."

If any check FAILS (e.g., the pipeline actually calls single embed() in a loop), fix the code to use the batch path.
  </action>
  <verify>
Read `rag-ingestion/src/bbj_rag/pipeline.py` and confirm `batch_size` parameter exists and `embed_batch()` is called.
Read `rag-ingestion/src/bbj_rag/embedder.py` and confirm `embed_batch()` passes a list to `ollama.embed(input=texts)`.
Run: `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run python -c "from bbj_rag.embedder import OllamaEmbedder; print('embed_batch' in dir(OllamaEmbedder))"`
Expected output: `True`
  </verify>
  <done>
Batch embedding path verified end-to-end: pipeline.py accumulates chunks in batches of 64 and calls embedder.embed_batch(), which passes the full list to ollama.embed(input=texts) in a single API call. No code changes needed -- the optimization was already in place. Finding documented in plan summary.
  </done>
</task>

</tasks>

<verification>
1. `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && uv run pytest tests/test_wordpress_parser.py -v` -- all tests pass
2. `cd /Users/beff/_workspace/bbj-ai-strategy/rag-ingestion && make check` -- lint, typecheck, full test suite green
3. `_is_pdf_url()` detects `.pdf` extension URLs
4. Content-Type header check detects redirected PDF responses
5. Both paths yield Documents with `metadata["format"] == "pdf"` and `doc_type == "article"`
6. `embedder.py` contains `embed_batch()` that passes a list to `ollama.embed(input=texts)`
7. `pipeline.py` uses `batch_size=64` and calls `embed_batch()` during ingestion
</verification>

<success_criteria>
WordPress parser handles PDFs via both URL extension and Content-Type header detection. All tests pass including new Content-Type tests. `make check` is green. Batch embedding verified as functional in the existing ingestion pipeline (no code changes needed).
</success_criteria>

<output>
After completion, create `.planning/phases/23.1-wordpress-parser-fix/23.1-01-SUMMARY.md`
</output>
