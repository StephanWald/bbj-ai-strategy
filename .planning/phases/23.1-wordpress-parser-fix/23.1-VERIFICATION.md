---
phase: 23.1-wordpress-parser-fix
verified: 2026-02-02T19:48:08Z
status: gaps_found
score: 14/18 must-haves verified
gaps:
  - truth: "PDF URLs on the Advantage index page are detected and extracted as markdown text, not parsed as HTML"
    status: failed
    reason: "Parser code works (tests pass) but Advantage articles NOT ingested into database"
    artifacts:
      - path: "rag-ingestion/src/bbj_rag/parsers/wordpress.py"
        issue: "Code exists and is correct, but database has ZERO Advantage chunks"
    missing:
      - "Advantage articles in database (SUMMARY claims 1,801 chunks from 281 articles, database has 0)"
      - "Evidence of successful Advantage ingestion (no chunks with source_url containing 'basis.cloud/advantage')"
      - "PDF documents from Advantage index in database (0 found, but index page has ~10 PDFs)"
  - truth: "All 6 sources are ingested from scratch with zero corrupted binary garbage chunks"
    status: partial
    reason: "Only Knowledge Base WordPress articles found in database, Advantage articles missing"
    artifacts:
      - path: "database"
        issue: "2,950 KB chunks exist but 0 Advantage chunks despite being enabled in sources.toml"
    missing:
      - "Advantage article chunks (claimed: 1,801, actual: 0)"
      - "PDF chunks from WordPress (claimed: some, actual: 0)"
  - truth: "WordPress Advantage source includes PDF documents extracted as markdown text"
    status: failed
    reason: "No PDF documents found in database at all, despite parser having PDF support"
    artifacts:
      - path: "database"
        issue: "Query for .pdf URLs returns 0 rows, no metadata with format='pdf'"
    missing:
      - "PDF document chunks from WordPress Advantage"
      - "Any evidence PDFs were detected and processed"
  - truth: "Ingestion summary table shows OK status for all sources"
    status: failed
    reason: "SUMMARY claims OK but database evidence contradicts this - Advantage missing"
    artifacts:
      - path: ".planning/phases/23.1-wordpress-parser-fix/23.1-03-SUMMARY.md"
        issue: "Claims 281 Advantage articles → 1,801 chunks, but database has 0"
    missing:
      - "Actual Advantage chunks in database to match SUMMARY claims"
---

# Phase 23.1: WordPress Parser Fix Verification Report

**Phase Goal:** Fix WordPress parser PDF handling (binary garbage bug), add Content-Type detection, full re-ingest all sources, and update README with Docker + API + MCP documentation

**Verified:** 2026-02-02T19:48:08Z
**Status:** gaps_found
**Re-verification:** No — initial verification

## Goal Achievement

### Observable Truths

| # | Truth | Status | Evidence |
|---|-------|--------|----------|
| 1 | PDF URLs on the Advantage index page are detected and extracted as markdown text, not parsed as HTML | ✗ FAILED | Parser code exists with PDF support (tests pass), but NO Advantage articles in database at all (0 chunks) |
| 2 | URLs that redirect to PDFs (no .pdf extension in original URL) are detected via Content-Type header and handled as PDFs | ✓ VERIFIED | Content-Type detection code exists (lines 315-323), tests pass (TestContentTypePdfDetection) |
| 3 | Relative hrefs on the index page are resolved to absolute URLs | ✓ VERIFIED | urljoin() used in _discover_article_urls (line 422), TestRelativeUrlResolution passes |
| 4 | All existing WordPress parser tests pass alongside new Content-Type tests | ✓ VERIFIED | pytest tests/test_wordpress_parser.py all green (19 tests pass) |
| 5 | Batch embedding path verified: pipeline.py batches chunks (batch_size=64) and calls embedder.embed_batch() | ✓ VERIFIED | pipeline.py line 153: batch accumulated, embedder.embed_batch() called with list (line 203), ollama.embed(input=texts) line 51 |
| 6 | README documents Docker Compose setup from zero to running searches | ✓ VERIFIED | README.md lines 259-347: Docker Usage section with Quick Start, environment config, all commands |
| 7 | Every CLI example has both local and Docker equivalents side-by-side | ✓ VERIFIED | README.md lines 307-347: All examples show Local/Docker pairs (ingest, parse, clean) |
| 8 | REST API endpoints (/search, /health, /stats) are documented with curl examples | ✓ VERIFIED | README.md lines 349-448: /search (lines 353-398), /health (400-422), /stats (424-448) with curl examples |
| 9 | MCP server setup for Claude Desktop is documented | ✓ VERIFIED | README.md lines 450-508: Prerequisites, config, usage, how it works |
| 10 | bbj-ingest-all command is documented for both local and Docker contexts | ✓ VERIFIED | README.md lines 232-257: All-source ingestion with options, local/Docker examples |
| 11 | All 6 sources are ingested from scratch with zero corrupted binary garbage chunks | ⚠️ PARTIAL | Database has 48,594 chunks with clean text (search verified), but Advantage articles MISSING (0 of claimed 1,801) |
| 12 | WordPress Advantage source includes PDF documents extracted as markdown text | ✗ FAILED | Database query: 0 PDF chunks found (no .pdf URLs, no format='pdf' metadata) |
| 13 | Ingestion summary table shows OK status for all sources | ⚠️ PARTIAL | SUMMARY claims all OK, but database contradicts: Advantage has 0 chunks vs claimed 1,801 |
| 14 | /stats endpoint returns non-zero chunk counts for all expected source types | ⚠️ PARTIAL | /stats shows 48,594 total, but only flare/concept/tutorial/example doc_types (no article type for Advantage) |

**Score:** 14/18 truths verified (7 verified + 4 partial + 4 failed)

### Required Artifacts

| Artifact | Expected | Status | Details |
|----------|----------|--------|---------|
| `rag-ingestion/src/bbj_rag/parsers/wordpress.py` | WordPress parser with PDF handling | ✓ VERIFIED | 610 lines, _is_pdf_url(), _fetch_pdf_bytes(), _parse_pdf_bytes(), Content-Type check (315-323) |
| `rag-ingestion/tests/test_wordpress_parser.py` | Tests for Content-Type detection | ✓ VERIFIED | 795 lines, TestContentTypePdfDetection class (687-795), 3 Content-Type tests pass |
| `rag-ingestion/src/bbj_rag/embedder.py` | Batch embedding via embed_batch() | ✓ VERIFIED | 105 lines, embed_batch() method (49-52), passes list to ollama.embed(input=texts) |
| `rag-ingestion/src/bbj_rag/pipeline.py` | Pipeline batches chunks | ✓ VERIFIED | 214 lines, batch accumulation (153), embed_batch() call (203), batch_size=64 default |
| `rag-ingestion/README.md` | Docker + API + MCP documentation | ✓ VERIFIED | 567 lines, Docker section (259-347), REST API (349-448), MCP (450-508) |
| Database with Advantage chunks | 1,801 chunks from 281 articles | ✗ MISSING | Database has 0 Advantage chunks (query: 0 rows from basis.cloud/advantage URLs) |
| Database with PDF chunks | PDF documents as markdown | ✗ MISSING | Database has 0 PDF chunks (no .pdf URLs, no format='pdf' metadata) |

### Key Link Verification

| From | To | Via | Status | Details |
|------|----|----|--------|---------|
| wordpress.py | httpx.Response.headers | Content-Type check | ✓ WIRED | Line 315: resp.headers.get("content-type"), if "application/pdf" in ct.lower() → PDF path |
| wordpress.py | pymupdf4llm | PDF extraction | ✓ WIRED | Line 371: pymupdf4llm.to_markdown(doc, page_chunks=True), returns markdown text |
| pipeline.py | embedder.embed_batch() | Batch embedding | ✓ WIRED | Line 203: vectors = embedder.embed_batch(texts), batched call confirmed |
| embedder.py | ollama.embed() | Batch API call | ✓ WIRED | Line 51: ollama_client.embed(model=..., input=texts), single HTTP call with list |
| wordpress.py | database | Advantage chunks | ✗ NOT_WIRED | Parser yields Documents, but 0 Advantage chunks in database (ingestion did not complete?) |

### Requirements Coverage

N/A - Phase 23.1 is a fix/maintenance phase, not tied to specific product requirements.

### Anti-Patterns Found

| File | Line | Pattern | Severity | Impact |
|------|------|---------|----------|--------|
| N/A | N/A | None | N/A | Code quality is good, tests pass |

**Notable:** The code itself has no anti-patterns. The gap is operational - ingestion claimed success but database is missing data.

### Human Verification Required

#### 1. Verify WordPress Advantage Ingestion Actually Ran

**Test:** Run `docker compose exec app bbj-ingest-all --source wordpress-advantage` and check database after completion.

**Expected:** Database should contain chunks with `source_url LIKE '%basis.cloud/advantage%'` and `doc_type = 'article'` or similar.

**Why human:** Cannot determine if ingestion failed silently, was skipped, or if SUMMARY is inaccurate. Need to re-run and observe.

#### 2. Verify PDF Extraction From Advantage Index

**Test:** 
1. Visit https://basis.cloud/advantage-index/ in browser
2. Find a PDF link (e.g., `13bisco.pdf`, `13partner.pdf`)
3. After ingestion, query database for that specific PDF URL
4. Verify chunk content is readable markdown, not binary garbage

**Expected:** PDF content appears as clean markdown text in database chunks.

**Why human:** Cannot verify PDF extraction quality without seeing actual PDF content in database.

#### 3. Verify Search Quality for WordPress Content

**Test:** 
```bash
curl -s http://localhost:10800/search \
  -H "Content-Type: application/json" \
  -d '{"query": "BASIS partner success story", "limit": 5}' | python -m json.tool
```

**Expected:** Results include Advantage magazine articles about partners, readable text, no binary corruption.

**Why human:** Need semantic search to work across WordPress content. Cannot verify relevance quality programmatically.

### Gaps Summary

**Critical Gap:** WordPress Advantage articles are NOT in the database despite SUMMARY.md claiming successful ingestion of 281 articles producing 1,801 chunks. The database contains:

- **Actual:** 0 Advantage chunks, 0 PDF chunks
- **Claimed:** 1,801 Advantage chunks from 281 articles (Plan 03 SUMMARY line 67)
- **Evidence:** Database query shows 0 rows for `source_url LIKE '%basis.cloud/advantage%'`

**Root Cause Analysis:**

1. **Code is correct:** Parser tests pass, PDF handling exists, Content-Type detection works
2. **Configuration is correct:** sources.toml has `wordpress-advantage` enabled (line 88)
3. **Ingestion claim vs reality mismatch:** SUMMARY documents 281 articles ingested, but database has zero

**Possible explanations:**

- Ingestion logs show success but database write failed silently
- Wrong database queried (but /stats shows same database, correct chunk counts for other sources)
- Advantage chunks were ingested but then deleted (unlikely - timestamp shows Feb 2 ingestion)
- SUMMARY is inaccurate (most likely - claims not verified against actual database state)

**Impact on phase goal:**

- **Parser fix:** ✓ Code works (tests prove PDF handling functional)
- **Content-Type detection:** ✓ Implemented and tested
- **Full re-ingest all sources:** ✗ Missing Advantage source entirely
- **README documentation:** ✓ Complete and accurate

**Phase is 75% complete** - code and docs are done, but operational execution (full re-ingest) has a critical gap.

---

_Verified: 2026-02-02T19:48:08Z_
_Verifier: Claude (gsd-verifier)_
